Epoch [271/300], Training Loss: 0.0010
Epoch [271/300], Test Loss: 0.0013
Epoch [272/300], Training Loss: 0.0011
Epoch [272/300], Test Loss: 0.0011
Epoch [273/300], Training Loss: 0.0011
Epoch [273/300], Test Loss: 0.0015
Epoch [274/300], Training Loss: 0.0010
Epoch [274/300], Test Loss: 0.0013
Epoch [275/300], Training Loss: 0.0010
Epoch [275/300], Test Loss: 0.0013
Epoch [276/300], Training Loss: 0.0010
Epoch [276/300], Test Loss: 0.0011
Epoch [277/300], Training Loss: 0.0011
Epoch [277/300], Test Loss: 0.0012
Epoch [278/300], Training Loss: 0.0010
Epoch [278/300], Test Loss: 0.0012
Epoch [279/300], Training Loss: 0.0010
Epoch [279/300], Test Loss: 0.0016
Epoch [280/300], Training Loss: 0.0010
Epoch [280/300], Test Loss: 0.0014
Model saved at epoch 280.
Epoch [281/300], Training Loss: 0.0011
Epoch [281/300], Test Loss: 0.0013
Epoch [282/300], Training Loss: 0.0009
Epoch [282/300], Test Loss: 0.0014
Epoch [283/300], Training Loss: 0.0010
Epoch [283/300], Test Loss: 0.0014
Epoch [284/300], Training Loss: 0.0011
Epoch [284/300], Test Loss: 0.0013
Epoch [285/300], Training Loss: 0.0010
Epoch [285/300], Test Loss: 0.0012
Epoch [286/300], Training Loss: 0.0010
Epoch [286/300], Test Loss: 0.0012
Epoch [287/300], Training Loss: 0.0010
Epoch [287/300], Test Loss: 0.0014
Epoch [288/300], Training Loss: 0.0010
Epoch [288/300], Test Loss: 0.0012
Epoch [289/300], Training Loss: 0.0009
Epoch [289/300], Test Loss: 0.0011
Epoch [290/300], Training Loss: 0.0010
Epoch [290/300], Test Loss: 0.0012
Model saved at epoch 290.
Epoch [291/300], Training Loss: 0.0010
Epoch [291/300], Test Loss: 0.0014
Epoch [292/300], Training Loss: 0.0009
Epoch [292/300], Test Loss: 0.0013
Epoch [293/300], Training Loss: 0.0009
Epoch [293/300], Test Loss: 0.0014
Epoch [294/300], Training Loss: 0.0009
Epoch [294/300], Test Loss: 0.0013
Epoch [295/300], Training Loss: 0.0010
Epoch [295/300], Test Loss: 0.0014
Epoch [296/300], Training Loss: 0.0010
Epoch [296/300], Test Loss: 0.0015
Epoch [297/300], Training Loss: 0.0009
Epoch [297/300], Test Loss: 0.0012
Epoch [298/300], Training Loss: 0.0009
Epoch [298/300], Test Loss: 0.0011
Epoch [299/300], Training Loss: 0.0010
Epoch [299/300], Test Loss: 0.0011
Epoch [300/300], Training Loss: 0.0009
Epoch [300/300], Test Loss: 0.0013
Model saved at epoch 300.

Found checkpoint. Last completed epoch: 300
Resuming training from epoch 300...
Epoch [301/700], Training Loss: 0.0010
Epoch [301/700], Test Loss: 0.0016
Epoch [302/700], Training Loss: 0.0009
Epoch [302/700], Test Loss: 0.0014
Epoch [303/700], Training Loss: 0.0010
Epoch [303/700], Test Loss: 0.0014
Epoch [304/700], Training Loss: 0.0010
Epoch [304/700], Test Loss: 0.0012
Epoch [305/700], Training Loss: 0.0010
Epoch [305/700], Test Loss: 0.0012
Epoch [306/700], Training Loss: 0.0010
Epoch [306/700], Test Loss: 0.0015
Epoch [307/700], Training Loss: 0.0010
Epoch [307/700], Test Loss: 0.0012
Epoch [308/700], Training Loss: 0.0010
Epoch [308/700], Test Loss: 0.0017
Epoch [309/700], Training Loss: 0.0009
Epoch [309/700], Test Loss: 0.0014
Epoch [310/700], Training Loss: 0.0009
Epoch [310/700], Test Loss: 0.0011
Model saved at epoch 310.
Epoch [311/700], Training Loss: 0.0009
Epoch [311/700], Test Loss: 0.0012
Epoch [312/700], Training Loss: 0.0009
Epoch [312/700], Test Loss: 0.0013
Epoch [313/700], Training Loss: 0.0009
Epoch [313/700], Test Loss: 0.0014
Epoch [314/700], Training Loss: 0.0009
Epoch [314/700], Test Loss: 0.0016
Epoch [315/700], Training Loss: 0.0009
Epoch [315/700], Test Loss: 0.0010
Epoch [316/700], Training Loss: 0.0008
Epoch [316/700], Test Loss: 0.0011
Epoch [317/700], Training Loss: 0.0009
Epoch [317/700], Test Loss: 0.0016
Epoch [318/700], Training Loss: 0.0009
Epoch [318/700], Test Loss: 0.0012
Epoch [319/700], Training Loss: 0.0010
Epoch [319/700], Test Loss: 0.0013
Epoch [320/700], Training Loss: 0.0009
Epoch [320/700], Test Loss: 0.0013
Model saved at epoch 320.
Epoch [321/700], Training Loss: 0.0008
Epoch [321/700], Test Loss: 0.0012
Epoch [322/700], Training Loss: 0.0009
Epoch [322/700], Test Loss: 0.0015
Epoch [323/700], Training Loss: 0.0009
Epoch [323/700], Test Loss: 0.0016
Epoch [324/700], Training Loss: 0.0009
Epoch [324/700], Test Loss: 0.0019
Epoch [325/700], Training Loss: 0.0009
Epoch [325/700], Test Loss: 0.0017
Epoch [326/700], Training Loss: 0.0009
Epoch [326/700], Test Loss: 0.0018
Epoch [327/700], Training Loss: 0.0009
Epoch [327/700], Test Loss: 0.0017
Epoch [328/700], Training Loss: 0.0009
Epoch [328/700], Test Loss: 0.0012
Epoch [329/700], Training Loss: 0.0008
Epoch [329/700], Test Loss: 0.0014
Epoch [330/700], Training Loss: 0.0008
Epoch [330/700], Test Loss: 0.0014
Model saved at epoch 330.
Epoch [331/700], Training Loss: 0.0008
Epoch [331/700], Test Loss: 0.0015
Epoch [332/700], Training Loss: 0.0008
Epoch [332/700], Test Loss: 0.0013
Epoch [333/700], Training Loss: 0.0008
Epoch [333/700], Test Loss: 0.0016
Epoch [334/700], Training Loss: 0.0009
Epoch [334/700], Test Loss: 0.0015
Epoch [335/700], Training Loss: 0.0009
Epoch [335/700], Test Loss: 0.0014
Epoch [336/700], Training Loss: 0.0009
Epoch [336/700], Test Loss: 0.0014
Epoch [337/700], Training Loss: 0.0008
Epoch [337/700], Test Loss: 0.0010
Epoch [338/700], Training Loss: 0.0008
Epoch [338/700], Test Loss: 0.0014
Epoch [339/700], Training Loss: 0.0008
Epoch [339/700], Test Loss: 0.0014
Epoch [340/700], Training Loss: 0.0008
Epoch [340/700], Test Loss: 0.0015
Model saved at epoch 340.
Epoch [341/700], Training Loss: 0.0009
Epoch [341/700], Test Loss: 0.0014
Epoch [342/700], Training Loss: 0.0008
Epoch [342/700], Test Loss: 0.0012
Epoch [343/700], Training Loss: 0.0008
Epoch [343/700], Test Loss: 0.0013
Epoch [344/700], Training Loss: 0.0008
Epoch [344/700], Test Loss: 0.0010
Epoch [345/700], Training Loss: 0.0008
Epoch [345/700], Test Loss: 0.0014
Epoch [346/700], Training Loss: 0.0008
Epoch [346/700], Test Loss: 0.0017
Epoch [347/700], Training Loss: 0.0008
Epoch [347/700], Test Loss: 0.0011
Epoch [348/700], Training Loss: 0.0009
Epoch [348/700], Test Loss: 0.0014
Epoch [349/700], Training Loss: 0.0008
Epoch [349/700], Test Loss: 0.0015
Epoch [350/700], Training Loss: 0.0008
Epoch [350/700], Test Loss: 0.0014
Model saved at epoch 350.
Epoch [351/700], Training Loss: 0.0008
Epoch [351/700], Test Loss: 0.0014
Epoch [352/700], Training Loss: 0.0008
Epoch [352/700], Test Loss: 0.0012
Epoch [353/700], Training Loss: 0.0009
Epoch [353/700], Test Loss: 0.0014
Epoch [354/700], Training Loss: 0.0008
Epoch [354/700], Test Loss: 0.0014
Epoch [355/700], Training Loss: 0.0008
Epoch [355/700], Test Loss: 0.0016
Epoch [356/700], Training Loss: 0.0008
Epoch [356/700], Test Loss: 0.0014
Epoch [357/700], Training Loss: 0.0008
Epoch [357/700], Test Loss: 0.0014
Epoch [358/700], Training Loss: 0.0007
Epoch [358/700], Test Loss: 0.0015
Epoch [359/700], Training Loss: 0.0008
Epoch [359/700], Test Loss: 0.0013
Epoch [360/700], Training Loss: 0.0007
Epoch [360/700], Test Loss: 0.0016
Model saved at epoch 360.
Epoch [361/700], Training Loss: 0.0008
Epoch [361/700], Test Loss: 0.0016
Epoch [362/700], Training Loss: 0.0009
Epoch [362/700], Test Loss: 0.0016
Epoch [363/700], Training Loss: 0.0007
Epoch [363/700], Test Loss: 0.0014
Epoch [364/700], Training Loss: 0.0008
Epoch [364/700], Test Loss: 0.0016
Epoch [365/700], Training Loss: 0.0008
Epoch [365/700], Test Loss: 0.0014
Epoch [366/700], Training Loss: 0.0008
Epoch [366/700], Test Loss: 0.0020
Epoch [367/700], Training Loss: 0.0008
Epoch [367/700], Test Loss: 0.0016
Epoch [368/700], Training Loss: 0.0008
Epoch [368/700], Test Loss: 0.0012
Epoch [369/700], Training Loss: 0.0008
Epoch [369/700], Test Loss: 0.0017
Epoch [370/700], Training Loss: 0.0008
Epoch [370/700], Test Loss: 0.0015
Model saved at epoch 370.
Epoch [371/700], Training Loss: 0.0008
Epoch [371/700], Test Loss: 0.0012
Epoch [372/700], Training Loss: 0.0008
Epoch [372/700], Test Loss: 0.0013
Epoch [373/700], Training Loss: 0.0008
Epoch [373/700], Test Loss: 0.0013
Epoch [374/700], Training Loss: 0.0007
Epoch [374/700], Test Loss: 0.0012
Epoch [375/700], Training Loss: 0.0008
Epoch [375/700], Test Loss: 0.0012
Epoch [376/700], Training Loss: 0.0008
Epoch [376/700], Test Loss: 0.0017
Epoch [377/700], Training Loss: 0.0008
Epoch [377/700], Test Loss: 0.0013
Epoch [378/700], Training Loss: 0.0008
Epoch [378/700], Test Loss: 0.0018
Epoch [379/700], Training Loss: 0.0008
Epoch [379/700], Test Loss: 0.0014
Epoch [380/700], Training Loss: 0.0008
Epoch [380/700], Test Loss: 0.0013
Model saved at epoch 380.
Epoch [381/700], Training Loss: 0.0008
Epoch [381/700], Test Loss: 0.0013
Epoch [382/700], Training Loss: 0.0008
Epoch [382/700], Test Loss: 0.0014
Epoch [383/700], Training Loss: 0.0007
Epoch [383/700], Test Loss: 0.0015
Epoch [384/700], Training Loss: 0.0007
Epoch [384/700], Test Loss: 0.0015
Epoch [385/700], Training Loss: 0.0007
Epoch [385/700], Test Loss: 0.0018
Epoch [386/700], Training Loss: 0.0008
Epoch [386/700], Test Loss: 0.0013
Epoch [387/700], Training Loss: 0.0008
Epoch [387/700], Test Loss: 0.0015
Epoch [388/700], Training Loss: 0.0008
Epoch [388/700], Test Loss: 0.0013
Epoch [389/700], Training Loss: 0.0008
Epoch [389/700], Test Loss: 0.0012
Epoch [390/700], Training Loss: 0.0008
Epoch [390/700], Test Loss: 0.0016
Model saved at epoch 390.
Epoch [391/700], Training Loss: 0.0007
Epoch [391/700], Test Loss: 0.0016
Epoch [392/700], Training Loss: 0.0007
Epoch [392/700], Test Loss: 0.0016
Epoch [393/700], Training Loss: 0.0007
Epoch [393/700], Test Loss: 0.0011
Epoch [394/700], Training Loss: 0.0007
Epoch [394/700], Test Loss: 0.0012
Epoch [395/700], Training Loss: 0.0007
Epoch [395/700], Test Loss: 0.0012
Epoch [396/700], Training Loss: 0.0007
Epoch [396/700], Test Loss: 0.0014
Epoch [397/700], Training Loss: 0.0007
Epoch [397/700], Test Loss: 0.0011
Epoch [398/700], Training Loss: 0.0007
Epoch [398/700], Test Loss: 0.0018
Epoch [399/700], Training Loss: 0.0007
Epoch [399/700], Test Loss: 0.0011
Epoch [400/700], Training Loss: 0.0007
Epoch [400/700], Test Loss: 0.0012
Model saved at epoch 400.
Epoch [401/700], Training Loss: 0.0007
Epoch [401/700], Test Loss: 0.0014
Epoch [402/700], Training Loss: 0.0007
Epoch [402/700], Test Loss: 0.0017
Epoch [403/700], Training Loss: 0.0007
Epoch [403/700], Test Loss: 0.0015
Epoch [404/700], Training Loss: 0.0007
Epoch [404/700], Test Loss: 0.0013
Epoch [405/700], Training Loss: 0.0007
Epoch [405/700], Test Loss: 0.0011
Epoch [406/700], Training Loss: 0.0007
Epoch [406/700], Test Loss: 0.0013
Epoch [407/700], Training Loss: 0.0007
Epoch [407/700], Test Loss: 0.0016
Epoch [408/700], Training Loss: 0.0007
Epoch [408/700], Test Loss: 0.0015
Epoch [409/700], Training Loss: 0.0007
Epoch [409/700], Test Loss: 0.0015
Epoch [410/700], Training Loss: 0.0007
Epoch [410/700], Test Loss: 0.0012
Model saved at epoch 410.
Epoch [411/700], Training Loss: 0.0007
Epoch [411/700], Test Loss: 0.0010
Epoch [412/700], Training Loss: 0.0007
Epoch [412/700], Test Loss: 0.0017
Epoch [413/700], Training Loss: 0.0007
Epoch [413/700], Test Loss: 0.0010
Epoch [414/700], Training Loss: 0.0007
Epoch [414/700], Test Loss: 0.0012
Epoch [415/700], Training Loss: 0.0007
Epoch [415/700], Test Loss: 0.0014
Epoch [416/700], Training Loss: 0.0008
Epoch [416/700], Test Loss: 0.0014
Epoch [417/700], Training Loss: 0.0007
Epoch [417/700], Test Loss: 0.0011
Epoch [418/700], Training Loss: 0.0007
Epoch [418/700], Test Loss: 0.0014
Epoch [419/700], Training Loss: 0.0007
Epoch [419/700], Test Loss: 0.0014
Epoch [420/700], Training Loss: 0.0006
Epoch [420/700], Test Loss: 0.0011
Model saved at epoch 420.
Epoch [421/700], Training Loss: 0.0006
Epoch [421/700], Test Loss: 0.0016
Epoch [422/700], Training Loss: 0.0006
Epoch [422/700], Test Loss: 0.0016
Epoch [423/700], Training Loss: 0.0006
Epoch [423/700], Test Loss: 0.0016
Epoch [424/700], Training Loss: 0.0006
Epoch [424/700], Test Loss: 0.0017
Epoch [425/700], Training Loss: 0.0006
Epoch [425/700], Test Loss: 0.0014
Epoch [426/700], Training Loss: 0.0007
Epoch [426/700], Test Loss: 0.0012
Epoch [427/700], Training Loss: 0.0006
Epoch [427/700], Test Loss: 0.0014
Epoch [428/700], Training Loss: 0.0007
Epoch [428/700], Test Loss: 0.0017
Epoch [429/700], Training Loss: 0.0006
Epoch [429/700], Test Loss: 0.0014
Epoch [430/700], Training Loss: 0.0007
Epoch [430/700], Test Loss: 0.0014
Model saved at epoch 430.
Epoch [431/700], Training Loss: 0.0006
Epoch [431/700], Test Loss: 0.0010
Epoch [432/700], Training Loss: 0.0007
Epoch [432/700], Test Loss: 0.0015
Epoch [433/700], Training Loss: 0.0007
Epoch [433/700], Test Loss: 0.0014
Epoch [434/700], Training Loss: 0.0006
Epoch [434/700], Test Loss: 0.0014
Epoch [435/700], Training Loss: 0.0007
Epoch [435/700], Test Loss: 0.0015
Epoch [436/700], Training Loss: 0.0006
Epoch [436/700], Test Loss: 0.0011
Epoch [437/700], Training Loss: 0.0006
Epoch [437/700], Test Loss: 0.0016
Epoch [438/700], Training Loss: 0.0006
Epoch [438/700], Test Loss: 0.0014
Epoch [439/700], Training Loss: 0.0007
Epoch [439/700], Test Loss: 0.0016
Epoch [440/700], Training Loss: 0.0006
Epoch [440/700], Test Loss: 0.0012
Model saved at epoch 440.
Epoch [441/700], Training Loss: 0.0007
Epoch [441/700], Test Loss: 0.0016
Epoch [442/700], Training Loss: 0.0007
Epoch [442/700], Test Loss: 0.0014
Epoch [443/700], Training Loss: 0.0006
Epoch [443/700], Test Loss: 0.0017
Epoch [444/700], Training Loss: 0.0006
Epoch [444/700], Test Loss: 0.0019
Epoch [445/700], Training Loss: 0.0007
Epoch [445/700], Test Loss: 0.0014
Epoch [446/700], Training Loss: 0.0007
Epoch [446/700], Test Loss: 0.0017
Epoch [447/700], Training Loss: 0.0007
Epoch [447/700], Test Loss: 0.0015
Epoch [448/700], Training Loss: 0.0006
Epoch [448/700], Test Loss: 0.0016
Epoch [449/700], Training Loss: 0.0006
Epoch [449/700], Test Loss: 0.0015
Epoch [450/700], Training Loss: 0.0006
Epoch [450/700], Test Loss: 0.0017
Model saved at epoch 450.
Epoch [451/700], Training Loss: 0.0007
Epoch [451/700], Test Loss: 0.0015
Epoch [452/700], Training Loss: 0.0006
Epoch [452/700], Test Loss: 0.0013
Epoch [453/700], Training Loss: 0.0006
Epoch [453/700], Test Loss: 0.0013
Epoch [454/700], Training Loss: 0.0006
Epoch [454/700], Test Loss: 0.0015
Epoch [455/700], Training Loss: 0.0007
Epoch [455/700], Test Loss: 0.0020
Epoch [456/700], Training Loss: 0.0007
Epoch [456/700], Test Loss: 0.0014
Epoch [457/700], Training Loss: 0.0006
Epoch [457/700], Test Loss: 0.0018
Epoch [458/700], Training Loss: 0.0006
Epoch [458/700], Test Loss: 0.0014
Epoch [459/700], Training Loss: 0.0006
Epoch [459/700], Test Loss: 0.0018
Epoch [460/700], Training Loss: 0.0006
Epoch [460/700], Test Loss: 0.0016
Model saved at epoch 460.
Epoch [461/700], Training Loss: 0.0006
Epoch [461/700], Test Loss: 0.0012
Epoch [462/700], Training Loss: 0.0006
Epoch [462/700], Test Loss: 0.0015
Epoch [463/700], Training Loss: 0.0006
Epoch [463/700], Test Loss: 0.0019
Epoch [464/700], Training Loss: 0.0006
Epoch [464/700], Test Loss: 0.0016
Epoch [465/700], Training Loss: 0.0006
Epoch [465/700], Test Loss: 0.0019
Epoch [466/700], Training Loss: 0.0006
Epoch [466/700], Test Loss: 0.0017
Epoch [467/700], Training Loss: 0.0006
Epoch [467/700], Test Loss: 0.0016
Epoch [468/700], Training Loss: 0.0006
Epoch [468/700], Test Loss: 0.0012
Epoch [469/700], Training Loss: 0.0006
Epoch [469/700], Test Loss: 0.0013
Epoch [470/700], Training Loss: 0.0006
Epoch [470/700], Test Loss: 0.0016
Model saved at epoch 470.
Epoch [471/700], Training Loss: 0.0006
Epoch [471/700], Test Loss: 0.0016
Epoch [472/700], Training Loss: 0.0006
Epoch [472/700], Test Loss: 0.0014
Epoch [473/700], Training Loss: 0.0006
Epoch [473/700], Test Loss: 0.0013
Epoch [474/700], Training Loss: 0.0006
Epoch [474/700], Test Loss: 0.0012
Epoch [475/700], Training Loss: 0.0006
Epoch [475/700], Test Loss: 0.0013
Epoch [476/700], Training Loss: 0.0006
Epoch [476/700], Test Loss: 0.0014
Epoch [477/700], Training Loss: 0.0006
Epoch [477/700], Test Loss: 0.0017
Epoch [478/700], Training Loss: 0.0005
Epoch [478/700], Test Loss: 0.0013
Epoch [479/700], Training Loss: 0.0005
Epoch [479/700], Test Loss: 0.0013
Epoch [480/700], Training Loss: 0.0006
Epoch [480/700], Test Loss: 0.0015
Model saved at epoch 480.
Epoch [481/700], Training Loss: 0.0006
Epoch [481/700], Test Loss: 0.0013
Epoch [482/700], Training Loss: 0.0006
Epoch [482/700], Test Loss: 0.0014
Epoch [483/700], Training Loss: 0.0006
Epoch [483/700], Test Loss: 0.0016
Epoch [484/700], Training Loss: 0.0006
Epoch [484/700], Test Loss: 0.0015
Epoch [485/700], Training Loss: 0.0006
Epoch [485/700], Test Loss: 0.0015
Epoch [486/700], Training Loss: 0.0006
Epoch [486/700], Test Loss: 0.0013
Epoch [487/700], Training Loss: 0.0006
Epoch [487/700], Test Loss: 0.0012
Epoch [488/700], Training Loss: 0.0006
Epoch [488/700], Test Loss: 0.0014
Epoch [489/700], Training Loss: 0.0006
Epoch [489/700], Test Loss: 0.0012
Epoch [490/700], Training Loss: 0.0006
Epoch [490/700], Test Loss: 0.0015
Model saved at epoch 490.
Epoch [491/700], Training Loss: 0.0006
Epoch [491/700], Test Loss: 0.0014
Epoch [492/700], Training Loss: 0.0006
Epoch [492/700], Test Loss: 0.0017
Epoch [493/700], Training Loss: 0.0005
Epoch [493/700], Test Loss: 0.0015
Epoch [494/700], Training Loss: 0.0006
Epoch [494/700], Test Loss: 0.0019
Epoch [495/700], Training Loss: 0.0006
Epoch [495/700], Test Loss: 0.0014
Epoch [496/700], Training Loss: 0.0006
Epoch [496/700], Test Loss: 0.0014
Epoch [497/700], Training Loss: 0.0006
Epoch [497/700], Test Loss: 0.0015
Epoch [498/700], Training Loss: 0.0006
Epoch [498/700], Test Loss: 0.0015
Epoch [499/700], Training Loss: 0.0006
Epoch [499/700], Test Loss: 0.0016
Epoch [500/700], Training Loss: 0.0006
Epoch [500/700], Test Loss: 0.0016
Model saved at epoch 500.
Epoch [501/700], Training Loss: 0.0006
Epoch [501/700], Test Loss: 0.0017
Epoch [502/700], Training Loss: 0.0006
Epoch [502/700], Test Loss: 0.0017
Epoch [503/700], Training Loss: 0.0006
Epoch [503/700], Test Loss: 0.0016
Epoch [504/700], Training Loss: 0.0006
Epoch [504/700], Test Loss: 0.0015
Epoch [505/700], Training Loss: 0.0005
Epoch [505/700], Test Loss: 0.0013
Epoch [506/700], Training Loss: 0.0005
Epoch [506/700], Test Loss: 0.0015
Epoch [507/700], Training Loss: 0.0006
Epoch [507/700], Test Loss: 0.0014
Epoch [508/700], Training Loss: 0.0006
Epoch [508/700], Test Loss: 0.0015
Epoch [509/700], Training Loss: 0.0006
Epoch [509/700], Test Loss: 0.0013
Epoch [510/700], Training Loss: 0.0005
Epoch [510/700], Test Loss: 0.0015
Model saved at epoch 510.
Epoch [511/700], Training Loss: 0.0005
Epoch [511/700], Test Loss: 0.0013
Epoch [512/700], Training Loss: 0.0005
Epoch [512/700], Test Loss: 0.0016
Epoch [513/700], Training Loss: 0.0005
Epoch [513/700], Test Loss: 0.0016
Epoch [514/700], Training Loss: 0.0005
Epoch [514/700], Test Loss: 0.0016
Epoch [515/700], Training Loss: 0.0005
Epoch [515/700], Test Loss: 0.0014
Epoch [516/700], Training Loss: 0.0005
Epoch [516/700], Test Loss: 0.0017
Epoch [517/700], Training Loss: 0.0005
Epoch [517/700], Test Loss: 0.0018
Epoch [518/700], Training Loss: 0.0005
Epoch [518/700], Test Loss: 0.0016
Epoch [519/700], Training Loss: 0.0005
Epoch [519/700], Test Loss: 0.0012
Epoch [520/700], Training Loss: 0.0006
Epoch [520/700], Test Loss: 0.0013
Model saved at epoch 520.
Epoch [521/700], Training Loss: 0.0006
Epoch [521/700], Test Loss: 0.0016
Epoch [522/700], Training Loss: 0.0006
Epoch [522/700], Test Loss: 0.0013
Epoch [523/700], Training Loss: 0.0005
Epoch [523/700], Test Loss: 0.0017
Epoch [524/700], Training Loss: 0.0005
Epoch [524/700], Test Loss: 0.0014
Epoch [525/700], Training Loss: 0.0006
Epoch [525/700], Test Loss: 0.0014
Epoch [526/700], Training Loss: 0.0006
Epoch [526/700], Test Loss: 0.0016
Epoch [527/700], Training Loss: 0.0006
Epoch [527/700], Test Loss: 0.0012
Epoch [528/700], Training Loss: 0.0006
Epoch [528/700], Test Loss: 0.0017
Epoch [529/700], Training Loss: 0.0006
Epoch [529/700], Test Loss: 0.0012
Epoch [530/700], Training Loss: 0.0006
Epoch [530/700], Test Loss: 0.0013
Model saved at epoch 530.
Epoch [531/700], Training Loss: 0.0006
Epoch [531/700], Test Loss: 0.0011
Epoch [532/700], Training Loss: 0.0005
Epoch [532/700], Test Loss: 0.0014
Epoch [533/700], Training Loss: 0.0005
Epoch [533/700], Test Loss: 0.0015
Epoch [534/700], Training Loss: 0.0005
Epoch [534/700], Test Loss: 0.0012
Epoch [535/700], Training Loss: 0.0006
Epoch [535/700], Test Loss: 0.0010
Epoch [536/700], Training Loss: 0.0005
Epoch [536/700], Test Loss: 0.0017
Epoch [537/700], Training Loss: 0.0005
Epoch [537/700], Test Loss: 0.0015
Epoch [538/700], Training Loss: 0.0005
Epoch [538/700], Test Loss: 0.0014
Epoch [539/700], Training Loss: 0.0005
Epoch [539/700], Test Loss: 0.0014
Epoch [540/700], Training Loss: 0.0005
Epoch [540/700], Test Loss: 0.0016
Model saved at epoch 540.
Epoch [541/700], Training Loss: 0.0006
Epoch [541/700], Test Loss: 0.0021
Epoch [542/700], Training Loss: 0.0005
Epoch [542/700], Test Loss: 0.0017
Epoch [543/700], Training Loss: 0.0005
Epoch [543/700], Test Loss: 0.0013
Epoch [544/700], Training Loss: 0.0005
Epoch [544/700], Test Loss: 0.0017
Epoch [545/700], Training Loss: 0.0005
Epoch [545/700], Test Loss: 0.0015
Epoch [546/700], Training Loss: 0.0006
Epoch [546/700], Test Loss: 0.0016
Epoch [547/700], Training Loss: 0.0005
Epoch [547/700], Test Loss: 0.0017
Epoch [548/700], Training Loss: 0.0005
Epoch [548/700], Test Loss: 0.0014
Epoch [549/700], Training Loss: 0.0005
Epoch [549/700], Test Loss: 0.0016
Epoch [550/700], Training Loss: 0.0005
Epoch [550/700], Test Loss: 0.0015
Model saved at epoch 550.
Epoch [551/700], Training Loss: 0.0005
Epoch [551/700], Test Loss: 0.0013
Epoch [552/700], Training Loss: 0.0005
Epoch [552/700], Test Loss: 0.0014
Epoch [553/700], Training Loss: 0.0005
Epoch [553/700], Test Loss: 0.0012
Epoch [554/700], Training Loss: 0.0005
Epoch [554/700], Test Loss: 0.0014
Epoch [555/700], Training Loss: 0.0005
Epoch [555/700], Test Loss: 0.0019
Epoch [556/700], Training Loss: 0.0005
Epoch [556/700], Test Loss: 0.0016
Epoch [557/700], Training Loss: 0.0005
Epoch [557/700], Test Loss: 0.0015
Epoch [558/700], Training Loss: 0.0005
Epoch [558/700], Test Loss: 0.0016
Epoch [559/700], Training Loss: 0.0005
Epoch [559/700], Test Loss: 0.0013
Epoch [560/700], Training Loss: 0.0005
Epoch [560/700], Test Loss: 0.0014
Model saved at epoch 560.
Epoch [561/700], Training Loss: 0.0005
Epoch [561/700], Test Loss: 0.0013
Epoch [562/700], Training Loss: 0.0005
Epoch [562/700], Test Loss: 0.0015
Epoch [563/700], Training Loss: 0.0005
Epoch [563/700], Test Loss: 0.0015
Epoch [564/700], Training Loss: 0.0005
Epoch [564/700], Test Loss: 0.0017
Epoch [565/700], Training Loss: 0.0005
Epoch [565/700], Test Loss: 0.0014
Epoch [566/700], Training Loss: 0.0005
Epoch [566/700], Test Loss: 0.0013
Epoch [567/700], Training Loss: 0.0005
Epoch [567/700], Test Loss: 0.0015
Epoch [568/700], Training Loss: 0.0005
Epoch [568/700], Test Loss: 0.0012
Epoch [569/700], Training Loss: 0.0005
Epoch [569/700], Test Loss: 0.0015
Epoch [570/700], Training Loss: 0.0005
Epoch [570/700], Test Loss: 0.0018
Model saved at epoch 570.
Epoch [571/700], Training Loss: 0.0005
Epoch [571/700], Test Loss: 0.0011
Epoch [572/700], Training Loss: 0.0005
Epoch [572/700], Test Loss: 0.0017
Epoch [573/700], Training Loss: 0.0005
Epoch [573/700], Test Loss: 0.0015
Epoch [574/700], Training Loss: 0.0005
Epoch [574/700], Test Loss: 0.0014
Epoch [575/700], Training Loss: 0.0005
Epoch [575/700], Test Loss: 0.0012
Epoch [576/700], Training Loss: 0.0005
Epoch [576/700], Test Loss: 0.0012
Epoch [577/700], Training Loss: 0.0005
Epoch [577/700], Test Loss: 0.0015
Epoch [578/700], Training Loss: 0.0005
Epoch [578/700], Test Loss: 0.0013
Epoch [579/700], Training Loss: 0.0005
Epoch [579/700], Test Loss: 0.0014
Epoch [580/700], Training Loss: 0.0005
Epoch [580/700], Test Loss: 0.0016
Model saved at epoch 580.
Epoch [581/700], Training Loss: 0.0005
Epoch [581/700], Test Loss: 0.0013
Epoch [582/700], Training Loss: 0.0004
Epoch [582/700], Test Loss: 0.0014
Epoch [583/700], Training Loss: 0.0004
Epoch [583/700], Test Loss: 0.0015
Epoch [584/700], Training Loss: 0.0005
Epoch [584/700], Test Loss: 0.0013
Epoch [585/700], Training Loss: 0.0005
Epoch [585/700], Test Loss: 0.0013
Epoch [586/700], Training Loss: 0.0004
Epoch [586/700], Test Loss: 0.0017
Epoch [587/700], Training Loss: 0.0005
Epoch [587/700], Test Loss: 0.0014
Epoch [588/700], Training Loss: 0.0005
Epoch [588/700], Test Loss: 0.0012
Epoch [589/700], Training Loss: 0.0005
Epoch [589/700], Test Loss: 0.0014
Epoch [590/700], Training Loss: 0.0005
Epoch [590/700], Test Loss: 0.0011
Model saved at epoch 590.
Epoch [591/700], Training Loss: 0.0005
Epoch [591/700], Test Loss: 0.0015
Epoch [592/700], Training Loss: 0.0005
Epoch [592/700], Test Loss: 0.0014
Epoch [593/700], Training Loss: 0.0005
Epoch [593/700], Test Loss: 0.0015
Epoch [594/700], Training Loss: 0.0005
Epoch [594/700], Test Loss: 0.0017
Epoch [595/700], Training Loss: 0.0005
Epoch [595/700], Test Loss: 0.0016
Epoch [596/700], Training Loss: 0.0006
Epoch [596/700], Test Loss: 0.0019
Epoch [597/700], Training Loss: 0.0005
Epoch [597/700], Test Loss: 0.0015
Epoch [598/700], Training Loss: 0.0005
Epoch [598/700], Test Loss: 0.0016
Epoch [599/700], Training Loss: 0.0005
Epoch [599/700], Test Loss: 0.0014
Epoch [600/700], Training Loss: 0.0004
Epoch [600/700], Test Loss: 0.0017
Model saved at epoch 600.
Epoch [601/700], Training Loss: 0.0005
Epoch [601/700], Test Loss: 0.0017
Epoch [602/700], Training Loss: 0.0004
Epoch [602/700], Test Loss: 0.0014
Epoch [603/700], Training Loss: 0.0004
Epoch [603/700], Test Loss: 0.0014
Epoch [604/700], Training Loss: 0.0005
Epoch [604/700], Test Loss: 0.0016
Epoch [605/700], Training Loss: 0.0005
Epoch [605/700], Test Loss: 0.0018
Epoch [606/700], Training Loss: 0.0005
Epoch [606/700], Test Loss: 0.0014
Epoch [607/700], Training Loss: 0.0005
Epoch [607/700], Test Loss: 0.0013
Epoch [608/700], Training Loss: 0.0005
Epoch [608/700], Test Loss: 0.0014
Epoch [609/700], Training Loss: 0.0005
Epoch [609/700], Test Loss: 0.0013
Epoch [610/700], Training Loss: 0.0004
Epoch [610/700], Test Loss: 0.0013
Model saved at epoch 610.
Epoch [611/700], Training Loss: 0.0005
Epoch [611/700], Test Loss: 0.0014
Epoch [612/700], Training Loss: 0.0004
Epoch [612/700], Test Loss: 0.0014
Epoch [613/700], Training Loss: 0.0004
Epoch [613/700], Test Loss: 0.0016
Epoch [614/700], Training Loss: 0.0005
Epoch [614/700], Test Loss: 0.0014
Epoch [615/700], Training Loss: 0.0005
Epoch [615/700], Test Loss: 0.0014
Epoch [616/700], Training Loss: 0.0005
Epoch [616/700], Test Loss: 0.0015
Epoch [617/700], Training Loss: 0.0004
Epoch [617/700], Test Loss: 0.0013
Epoch [618/700], Training Loss: 0.0005
Epoch [618/700], Test Loss: 0.0012
Epoch [619/700], Training Loss: 0.0005
Epoch [619/700], Test Loss: 0.0017
Epoch [620/700], Training Loss: 0.0004
Epoch [620/700], Test Loss: 0.0011
Model saved at epoch 620.
Epoch [621/700], Training Loss: 0.0004
Epoch [621/700], Test Loss: 0.0010
Epoch [622/700], Training Loss: 0.0004
Epoch [622/700], Test Loss: 0.0020
Epoch [623/700], Training Loss: 0.0004
Epoch [623/700], Test Loss: 0.0017
Epoch [624/700], Training Loss: 0.0005
Epoch [624/700], Test Loss: 0.0016
Epoch [625/700], Training Loss: 0.0004
Epoch [625/700], Test Loss: 0.0014
Epoch [626/700], Training Loss: 0.0004
Epoch [626/700], Test Loss: 0.0015
Epoch [627/700], Training Loss: 0.0004
Epoch [627/700], Test Loss: 0.0014
Epoch [628/700], Training Loss: 0.0004
Epoch [628/700], Test Loss: 0.0018
Epoch [629/700], Training Loss: 0.0004
Epoch [629/700], Test Loss: 0.0014
Epoch [630/700], Training Loss: 0.0004
Epoch [630/700], Test Loss: 0.0013
Model saved at epoch 630.
Epoch [631/700], Training Loss: 0.0005
Epoch [631/700], Test Loss: 0.0013
Epoch [632/700], Training Loss: 0.0005
Epoch [632/700], Test Loss: 0.0012
Epoch [633/700], Training Loss: 0.0004
Epoch [633/700], Test Loss: 0.0014
Epoch [634/700], Training Loss: 0.0005
Epoch [634/700], Test Loss: 0.0016
Epoch [635/700], Training Loss: 0.0005
Epoch [635/700], Test Loss: 0.0016
Epoch [636/700], Training Loss: 0.0005
Epoch [636/700], Test Loss: 0.0015
Epoch [637/700], Training Loss: 0.0004
Epoch [637/700], Test Loss: 0.0013
Epoch [638/700], Training Loss: 0.0005
Epoch [638/700], Test Loss: 0.0014
Epoch [639/700], Training Loss: 0.0004
Epoch [639/700], Test Loss: 0.0014
Epoch [640/700], Training Loss: 0.0005
Epoch [640/700], Test Loss: 0.0012
Model saved at epoch 640.
Epoch [641/700], Training Loss: 0.0005
Epoch [641/700], Test Loss: 0.0014
Epoch [642/700], Training Loss: 0.0005
Epoch [642/700], Test Loss: 0.0012
Epoch [643/700], Training Loss: 0.0005
Epoch [643/700], Test Loss: 0.0018
Epoch [644/700], Training Loss: 0.0005
Epoch [644/700], Test Loss: 0.0012
Epoch [645/700], Training Loss: 0.0004
Epoch [645/700], Test Loss: 0.0013
Epoch [646/700], Training Loss: 0.0005
Epoch [646/700], Test Loss: 0.0018
Epoch [647/700], Training Loss: 0.0004
Epoch [647/700], Test Loss: 0.0020
Epoch [648/700], Training Loss: 0.0004
Epoch [648/700], Test Loss: 0.0016
Epoch [649/700], Training Loss: 0.0005
Epoch [649/700], Test Loss: 0.0017
Epoch [650/700], Training Loss: 0.0004
Epoch [650/700], Test Loss: 0.0012
Model saved at epoch 650.
Epoch [651/700], Training Loss: 0.0004
Epoch [651/700], Test Loss: 0.0013
Epoch [652/700], Training Loss: 0.0005
Epoch [652/700], Test Loss: 0.0018
Epoch [653/700], Training Loss: 0.0005
Epoch [653/700], Test Loss: 0.0017
Epoch [654/700], Training Loss: 0.0004
Epoch [654/700], Test Loss: 0.0015
Epoch [655/700], Training Loss: 0.0005
Epoch [655/700], Test Loss: 0.0020
Epoch [656/700], Training Loss: 0.0005
Epoch [656/700], Test Loss: 0.0014
Epoch [657/700], Training Loss: 0.0004
Epoch [657/700], Test Loss: 0.0009
Epoch [658/700], Training Loss: 0.0004
Epoch [658/700], Test Loss: 0.0016
Epoch [659/700], Training Loss: 0.0004
Epoch [659/700], Test Loss: 0.0011
Epoch [660/700], Training Loss: 0.0004
Epoch [660/700], Test Loss: 0.0014
Model saved at epoch 660.
Epoch [661/700], Training Loss: 0.0004
Epoch [661/700], Test Loss: 0.0014
Epoch [662/700], Training Loss: 0.0005
Epoch [662/700], Test Loss: 0.0018
Epoch [663/700], Training Loss: 0.0004
Epoch [663/700], Test Loss: 0.0013
Epoch [664/700], Training Loss: 0.0004
Epoch [664/700], Test Loss: 0.0015
Epoch [665/700], Training Loss: 0.0004
Epoch [665/700], Test Loss: 0.0022
Epoch [666/700], Training Loss: 0.0004
Epoch [666/700], Test Loss: 0.0015
Epoch [667/700], Training Loss: 0.0004
Epoch [667/700], Test Loss: 0.0012
Epoch [668/700], Training Loss: 0.0004
Epoch [668/700], Test Loss: 0.0016
Epoch [669/700], Training Loss: 0.0005
Epoch [669/700], Test Loss: 0.0014
Epoch [670/700], Training Loss: 0.0004
Epoch [670/700], Test Loss: 0.0015
Model saved at epoch 670.
Epoch [671/700], Training Loss: 0.0004
Epoch [671/700], Test Loss: 0.0015
Epoch [672/700], Training Loss: 0.0004
Epoch [672/700], Test Loss: 0.0015
Epoch [673/700], Training Loss: 0.0004
Epoch [673/700], Test Loss: 0.0016
Epoch [674/700], Training Loss: 0.0004
Epoch [674/700], Test Loss: 0.0014
Epoch [675/700], Training Loss: 0.0004
Epoch [675/700], Test Loss: 0.0015
Epoch [676/700], Training Loss: 0.0004
Epoch [676/700], Test Loss: 0.0016
Epoch [677/700], Training Loss: 0.0004
Epoch [677/700], Test Loss: 0.0015
Epoch [678/700], Training Loss: 0.0004
Epoch [678/700], Test Loss: 0.0013
Epoch [679/700], Training Loss: 0.0004
Epoch [679/700], Test Loss: 0.0013
Epoch [680/700], Training Loss: 0.0004
Epoch [680/700], Test Loss: 0.0010
Model saved at epoch 680.
Epoch [681/700], Training Loss: 0.0004
Epoch [681/700], Test Loss: 0.0016
Epoch [682/700], Training Loss: 0.0005
Epoch [682/700], Test Loss: 0.0013
Epoch [683/700], Training Loss: 0.0004
Epoch [683/700], Test Loss: 0.0013
Epoch [684/700], Training Loss: 0.0004
Epoch [684/700], Test Loss: 0.0016
Epoch [685/700], Training Loss: 0.0004
Epoch [685/700], Test Loss: 0.0013
Epoch [686/700], Training Loss: 0.0004
Epoch [686/700], Test Loss: 0.0010
Epoch [687/700], Training Loss: 0.0004
Epoch [687/700], Test Loss: 0.0017
Epoch [688/700], Training Loss: 0.0004
Epoch [688/700], Test Loss: 0.0015
Epoch [689/700], Training Loss: 0.0004
Epoch [689/700], Test Loss: 0.0013
Epoch [690/700], Training Loss: 0.0004
Epoch [690/700], Test Loss: 0.0014
Model saved at epoch 690.
Epoch [691/700], Training Loss: 0.0005
Epoch [691/700], Test Loss: 0.0015
Epoch [692/700], Training Loss: 0.0004
Epoch [692/700], Test Loss: 0.0016
Epoch [693/700], Training Loss: 0.0004
Epoch [693/700], Test Loss: 0.0015
Epoch [694/700], Training Loss: 0.0004
Epoch [694/700], Test Loss: 0.0021
Epoch [695/700], Training Loss: 0.0004
Epoch [695/700], Test Loss: 0.0015
Epoch [696/700], Training Loss: 0.0004
Epoch [696/700], Test Loss: 0.0013
Epoch [697/700], Training Loss: 0.0004
Epoch [697/700], Test Loss: 0.0014
Epoch [698/700], Training Loss: 0.0004
Epoch [698/700], Test Loss: 0.0016
Epoch [699/700], Training Loss: 0.0005
Epoch [699/700], Test Loss: 0.0015
Epoch [700/700], Training Loss: 0.0004
Epoch [700/700], Test Loss: 0.0014
Model saved at epoch 700.

Epoch [701/1250], Training Loss: 0.0004
Epoch [701/1250], Test Loss: 0.0015
Epoch [702/1250], Training Loss: 0.0004
Epoch [702/1250], Test Loss: 0.0020
Epoch [703/1250], Training Loss: 0.0004
Epoch [703/1250], Test Loss: 0.0016
Epoch [704/1250], Training Loss: 0.0004
Epoch [704/1250], Test Loss: 0.0012
Epoch [705/1250], Training Loss: 0.0004
Epoch [705/1250], Test Loss: 0.0013
Epoch [706/1250], Training Loss: 0.0004
Epoch [706/1250], Test Loss: 0.0014
Epoch [707/1250], Training Loss: 0.0004
Epoch [707/1250], Test Loss: 0.0015
Epoch [708/1250], Training Loss: 0.0004
Epoch [708/1250], Test Loss: 0.0013
Epoch [709/1250], Training Loss: 0.0004
Epoch [709/1250], Test Loss: 0.0017
Epoch [710/1250], Training Loss: 0.0004
Epoch [710/1250], Test Loss: 0.0014
Model saved at epoch 710.

Found checkpoint. Last completed epoch: 710
Resuming training from epoch 710...
Epoch [711/1250], Training Loss: 0.0004
Epoch [711/1250], Test Loss: 0.0019
Epoch [712/1250], Training Loss: 0.0004
Epoch [712/1250], Test Loss: 0.0015
Epoch [713/1250], Training Loss: 0.0004
Epoch [713/1250], Test Loss: 0.0016
Epoch [714/1250], Training Loss: 0.0004
Epoch [714/1250], Test Loss: 0.0013
Epoch [715/1250], Training Loss: 0.0004
Epoch [715/1250], Test Loss: 0.0015
Epoch [716/1250], Training Loss: 0.0004
Epoch [716/1250], Test Loss: 0.0013
Epoch [717/1250], Training Loss: 0.0004
Epoch [717/1250], Test Loss: 0.0016
Epoch [718/1250], Training Loss: 0.0004
Epoch [718/1250], Test Loss: 0.0012
Epoch [719/1250], Training Loss: 0.0004
Epoch [719/1250], Test Loss: 0.0015
Epoch [720/1250], Training Loss: 0.0004
Epoch [720/1250], Test Loss: 0.0013
Model saved at epoch 720.
Epoch [721/1250], Training Loss: 0.0004
Epoch [721/1250], Test Loss: 0.0013
Epoch [722/1250], Training Loss: 0.0004
Epoch [722/1250], Test Loss: 0.0016
Epoch [723/1250], Training Loss: 0.0004
Epoch [723/1250], Test Loss: 0.0017
Epoch [724/1250], Training Loss: 0.0004
Epoch [724/1250], Test Loss: 0.0014
Epoch [725/1250], Training Loss: 0.0004
Epoch [725/1250], Test Loss: 0.0015
Epoch [726/1250], Training Loss: 0.0004
Epoch [726/1250], Test Loss: 0.0014
Epoch [727/1250], Training Loss: 0.0004
Epoch [727/1250], Test Loss: 0.0013
Epoch [728/1250], Training Loss: 0.0004
Epoch [728/1250], Test Loss: 0.0017
Epoch [729/1250], Training Loss: 0.0004
Epoch [729/1250], Test Loss: 0.0014
Epoch [730/1250], Training Loss: 0.0004
Epoch [730/1250], Test Loss: 0.0017
Model saved at epoch 730.
Epoch [731/1250], Training Loss: 0.0004
Epoch [731/1250], Test Loss: 0.0019
Epoch [732/1250], Training Loss: 0.0004
Epoch [732/1250], Test Loss: 0.0014
Epoch [733/1250], Training Loss: 0.0004
Epoch [733/1250], Test Loss: 0.0020
Epoch [734/1250], Training Loss: 0.0004
Epoch [734/1250], Test Loss: 0.0017
Epoch [735/1250], Training Loss: 0.0004
Epoch [735/1250], Test Loss: 0.0014
Epoch [736/1250], Training Loss: 0.0004
Epoch [736/1250], Test Loss: 0.0015
Epoch [737/1250], Training Loss: 0.0004
Epoch [737/1250], Test Loss: 0.0020
Epoch [738/1250], Training Loss: 0.0004
Epoch [738/1250], Test Loss: 0.0013
Epoch [739/1250], Training Loss: 0.0004
Epoch [739/1250], Test Loss: 0.0013
Epoch [740/1250], Training Loss: 0.0004
Epoch [740/1250], Test Loss: 0.0013
Model saved at epoch 740.
Epoch [741/1250], Training Loss: 0.0004
Epoch [741/1250], Test Loss: 0.0018
Epoch [742/1250], Training Loss: 0.0004
Epoch [742/1250], Test Loss: 0.0017
Epoch [743/1250], Training Loss: 0.0004
Epoch [743/1250], Test Loss: 0.0019
Epoch [744/1250], Training Loss: 0.0004
Epoch [744/1250], Test Loss: 0.0013
Epoch [745/1250], Training Loss: 0.0004
Epoch [745/1250], Test Loss: 0.0021
Epoch [746/1250], Training Loss: 0.0004
Epoch [746/1250], Test Loss: 0.0016
Epoch [747/1250], Training Loss: 0.0004
Epoch [747/1250], Test Loss: 0.0014
Epoch [748/1250], Training Loss: 0.0004
Epoch [748/1250], Test Loss: 0.0016
Epoch [749/1250], Training Loss: 0.0004
Epoch [749/1250], Test Loss: 0.0014
Epoch [750/1250], Training Loss: 0.0004
Epoch [750/1250], Test Loss: 0.0017
Model saved at epoch 750.
Epoch [751/1250], Training Loss: 0.0004
Epoch [751/1250], Test Loss: 0.0016
Epoch [752/1250], Training Loss: 0.0004
Epoch [752/1250], Test Loss: 0.0013
Epoch [753/1250], Training Loss: 0.0004
Epoch [753/1250], Test Loss: 0.0016
Epoch [754/1250], Training Loss: 0.0004
Epoch [754/1250], Test Loss: 0.0013
Epoch [755/1250], Training Loss: 0.0004
Epoch [755/1250], Test Loss: 0.0015
Epoch [756/1250], Training Loss: 0.0004
Epoch [756/1250], Test Loss: 0.0018
Epoch [757/1250], Training Loss: 0.0004
Epoch [757/1250], Test Loss: 0.0014
Epoch [758/1250], Training Loss: 0.0004
Epoch [758/1250], Test Loss: 0.0019
Epoch [759/1250], Training Loss: 0.0004
Epoch [759/1250], Test Loss: 0.0012
Epoch [760/1250], Training Loss: 0.0004
Epoch [760/1250], Test Loss: 0.0013
Model saved at epoch 760.
Epoch [761/1250], Training Loss: 0.0004
Epoch [761/1250], Test Loss: 0.0015
Epoch [762/1250], Training Loss: 0.0004
Epoch [762/1250], Test Loss: 0.0014
Epoch [763/1250], Training Loss: 0.0004
Epoch [763/1250], Test Loss: 0.0011
Epoch [764/1250], Training Loss: 0.0004
Epoch [764/1250], Test Loss: 0.0020
Epoch [765/1250], Training Loss: 0.0004
Epoch [765/1250], Test Loss: 0.0016
Epoch [766/1250], Training Loss: 0.0004
Epoch [766/1250], Test Loss: 0.0015
Epoch [767/1250], Training Loss: 0.0004
Epoch [767/1250], Test Loss: 0.0011
Epoch [768/1250], Training Loss: 0.0004
Epoch [768/1250], Test Loss: 0.0014
Epoch [769/1250], Training Loss: 0.0004
Epoch [769/1250], Test Loss: 0.0014
Epoch [770/1250], Training Loss: 0.0004
Epoch [770/1250], Test Loss: 0.0019
Model saved at epoch 770.
Epoch [771/1250], Training Loss: 0.0004
Epoch [771/1250], Test Loss: 0.0013
Epoch [772/1250], Training Loss: 0.0004
Epoch [772/1250], Test Loss: 0.0016
Epoch [773/1250], Training Loss: 0.0004
Epoch [773/1250], Test Loss: 0.0017
Epoch [774/1250], Training Loss: 0.0004
Epoch [774/1250], Test Loss: 0.0014
Epoch [775/1250], Training Loss: 0.0004
Epoch [775/1250], Test Loss: 0.0015
Epoch [776/1250], Training Loss: 0.0004
Epoch [776/1250], Test Loss: 0.0013
Epoch [777/1250], Training Loss: 0.0004
Epoch [777/1250], Test Loss: 0.0012
Epoch [778/1250], Training Loss: 0.0004
Epoch [778/1250], Test Loss: 0.0016
Epoch [779/1250], Training Loss: 0.0004
Epoch [779/1250], Test Loss: 0.0017
Epoch [780/1250], Training Loss: 0.0004
Epoch [780/1250], Test Loss: 0.0016
Model saved at epoch 780.
Epoch [781/1250], Training Loss: 0.0004
Epoch [781/1250], Test Loss: 0.0016
Epoch [782/1250], Training Loss: 0.0004
Epoch [782/1250], Test Loss: 0.0016
Epoch [783/1250], Training Loss: 0.0004
Epoch [783/1250], Test Loss: 0.0017
Epoch [784/1250], Training Loss: 0.0004
Epoch [784/1250], Test Loss: 0.0016
Epoch [785/1250], Training Loss: 0.0004
Epoch [785/1250], Test Loss: 0.0012
Epoch [786/1250], Training Loss: 0.0004
Epoch [786/1250], Test Loss: 0.0016
Epoch [787/1250], Training Loss: 0.0004
Epoch [787/1250], Test Loss: 0.0023
Epoch [788/1250], Training Loss: 0.0004
Epoch [788/1250], Test Loss: 0.0016
Epoch [789/1250], Training Loss: 0.0004
Epoch [789/1250], Test Loss: 0.0015
Epoch [790/1250], Training Loss: 0.0004
Epoch [790/1250], Test Loss: 0.0016
Model saved at epoch 790.
Epoch [791/1250], Training Loss: 0.0004
Epoch [791/1250], Test Loss: 0.0014
Epoch [792/1250], Training Loss: 0.0004
Epoch [792/1250], Test Loss: 0.0016
Epoch [793/1250], Training Loss: 0.0004
Epoch [793/1250], Test Loss: 0.0017
Epoch [794/1250], Training Loss: 0.0004
Epoch [794/1250], Test Loss: 0.0016
Epoch [795/1250], Training Loss: 0.0004
Epoch [795/1250], Test Loss: 0.0015
Epoch [796/1250], Training Loss: 0.0004
Epoch [796/1250], Test Loss: 0.0017
Epoch [797/1250], Training Loss: 0.0004
Epoch [797/1250], Test Loss: 0.0014
Epoch [798/1250], Training Loss: 0.0003
Epoch [798/1250], Test Loss: 0.0011
Epoch [799/1250], Training Loss: 0.0003
Epoch [799/1250], Test Loss: 0.0017
Epoch [800/1250], Training Loss: 0.0003
Epoch [800/1250], Test Loss: 0.0024
Model saved at epoch 800.
Epoch [801/1250], Training Loss: 0.0004
Epoch [801/1250], Test Loss: 0.0016
Epoch [802/1250], Training Loss: 0.0004
Epoch [802/1250], Test Loss: 0.0013
Epoch [803/1250], Training Loss: 0.0004
Epoch [803/1250], Test Loss: 0.0018
Epoch [804/1250], Training Loss: 0.0003
Epoch [804/1250], Test Loss: 0.0015
Epoch [805/1250], Training Loss: 0.0003
Epoch [805/1250], Test Loss: 0.0016
Epoch [806/1250], Training Loss: 0.0003
Epoch [806/1250], Test Loss: 0.0012
Epoch [807/1250], Training Loss: 0.0004
Epoch [807/1250], Test Loss: 0.0014
Epoch [808/1250], Training Loss: 0.0004
Epoch [808/1250], Test Loss: 0.0013
Epoch [809/1250], Training Loss: 0.0004
Epoch [809/1250], Test Loss: 0.0017
Epoch [810/1250], Training Loss: 0.0004
Epoch [810/1250], Test Loss: 0.0014
Model saved at epoch 810.
Epoch [811/1250], Training Loss: 0.0003
Epoch [811/1250], Test Loss: 0.0012
Epoch [812/1250], Training Loss: 0.0004
Epoch [812/1250], Test Loss: 0.0016
Epoch [813/1250], Training Loss: 0.0003
Epoch [813/1250], Test Loss: 0.0018
Epoch [814/1250], Training Loss: 0.0003
Epoch [814/1250], Test Loss: 0.0015
Epoch [815/1250], Training Loss: 0.0004
Epoch [815/1250], Test Loss: 0.0017
Epoch [816/1250], Training Loss: 0.0004
Epoch [816/1250], Test Loss: 0.0021
Epoch [817/1250], Training Loss: 0.0004
Epoch [817/1250], Test Loss: 0.0015
Epoch [818/1250], Training Loss: 0.0003
Epoch [818/1250], Test Loss: 0.0012
Epoch [819/1250], Training Loss: 0.0003
Epoch [819/1250], Test Loss: 0.0015
Epoch [820/1250], Training Loss: 0.0004
Epoch [820/1250], Test Loss: 0.0012
Model saved at epoch 820.
Epoch [821/1250], Training Loss: 0.0003
Epoch [821/1250], Test Loss: 0.0014
Epoch [822/1250], Training Loss: 0.0003
Epoch [822/1250], Test Loss: 0.0015
Epoch [823/1250], Training Loss: 0.0004
Epoch [823/1250], Test Loss: 0.0017
Epoch [824/1250], Training Loss: 0.0004
Epoch [824/1250], Test Loss: 0.0015
Epoch [825/1250], Training Loss: 0.0004
Epoch [825/1250], Test Loss: 0.0013
Epoch [826/1250], Training Loss: 0.0004
Epoch [826/1250], Test Loss: 0.0014
Epoch [827/1250], Training Loss: 0.0003
Epoch [827/1250], Test Loss: 0.0013
Epoch [828/1250], Training Loss: 0.0004
Epoch [828/1250], Test Loss: 0.0014
Epoch [829/1250], Training Loss: 0.0003
Epoch [829/1250], Test Loss: 0.0009
Epoch [830/1250], Training Loss: 0.0003
Epoch [830/1250], Test Loss: 0.0012
Model saved at epoch 830.
Epoch [831/1250], Training Loss: 0.0004
Epoch [831/1250], Test Loss: 0.0015
Epoch [832/1250], Training Loss: 0.0004
Epoch [832/1250], Test Loss: 0.0013
Epoch [833/1250], Training Loss: 0.0004
Epoch [833/1250], Test Loss: 0.0013
Epoch [834/1250], Training Loss: 0.0004
Epoch [834/1250], Test Loss: 0.0014
Epoch [835/1250], Training Loss: 0.0004
Epoch [835/1250], Test Loss: 0.0014
Epoch [836/1250], Training Loss: 0.0003
Epoch [836/1250], Test Loss: 0.0017
Epoch [837/1250], Training Loss: 0.0003
Epoch [837/1250], Test Loss: 0.0018
Epoch [838/1250], Training Loss: 0.0003
Epoch [838/1250], Test Loss: 0.0016
Epoch [839/1250], Training Loss: 0.0003
Epoch [839/1250], Test Loss: 0.0017
Epoch [840/1250], Training Loss: 0.0003
Epoch [840/1250], Test Loss: 0.0014
Model saved at epoch 840.
Epoch [841/1250], Training Loss: 0.0003
Epoch [841/1250], Test Loss: 0.0013
Epoch [842/1250], Training Loss: 0.0003
Epoch [842/1250], Test Loss: 0.0015
Epoch [843/1250], Training Loss: 0.0003
Epoch [843/1250], Test Loss: 0.0019
Epoch [844/1250], Training Loss: 0.0004
Epoch [844/1250], Test Loss: 0.0015
Epoch [845/1250], Training Loss: 0.0003
Epoch [845/1250], Test Loss: 0.0019
Epoch [846/1250], Training Loss: 0.0004
Epoch [846/1250], Test Loss: 0.0017
Epoch [847/1250], Training Loss: 0.0003
Epoch [847/1250], Test Loss: 0.0013
Epoch [848/1250], Training Loss: 0.0004
Epoch [848/1250], Test Loss: 0.0013
Epoch [849/1250], Training Loss: 0.0003
Epoch [849/1250], Test Loss: 0.0014
Epoch [850/1250], Training Loss: 0.0004
Epoch [850/1250], Test Loss: 0.0015
Model saved at epoch 850.
Epoch [851/1250], Training Loss: 0.0004
Epoch [851/1250], Test Loss: 0.0012
Epoch [852/1250], Training Loss: 0.0003
Epoch [852/1250], Test Loss: 0.0020
Epoch [853/1250], Training Loss: 0.0004
Epoch [853/1250], Test Loss: 0.0017
Epoch [854/1250], Training Loss: 0.0004
Epoch [854/1250], Test Loss: 0.0017
Epoch [855/1250], Training Loss: 0.0003
Epoch [855/1250], Test Loss: 0.0011
Epoch [856/1250], Training Loss: 0.0003
Epoch [856/1250], Test Loss: 0.0016
Epoch [857/1250], Training Loss: 0.0003
Epoch [857/1250], Test Loss: 0.0014
Epoch [858/1250], Training Loss: 0.0003
Epoch [858/1250], Test Loss: 0.0013
Epoch [859/1250], Training Loss: 0.0003
Epoch [859/1250], Test Loss: 0.0015
Epoch [860/1250], Training Loss: 0.0003
Epoch [860/1250], Test Loss: 0.0016
Model saved at epoch 860.
Epoch [861/1250], Training Loss: 0.0003
Epoch [861/1250], Test Loss: 0.0019
Epoch [862/1250], Training Loss: 0.0004
Epoch [862/1250], Test Loss: 0.0016
Epoch [863/1250], Training Loss: 0.0003
Epoch [863/1250], Test Loss: 0.0011
Epoch [864/1250], Training Loss: 0.0003
Epoch [864/1250], Test Loss: 0.0014
Epoch [865/1250], Training Loss: 0.0003
Epoch [865/1250], Test Loss: 0.0022
Epoch [866/1250], Training Loss: 0.0004
Epoch [866/1250], Test Loss: 0.0014
Epoch [867/1250], Training Loss: 0.0004
Epoch [867/1250], Test Loss: 0.0013
Epoch [868/1250], Training Loss: 0.0003
Epoch [868/1250], Test Loss: 0.0014
Epoch [869/1250], Training Loss: 0.0004
Epoch [869/1250], Test Loss: 0.0016
Epoch [870/1250], Training Loss: 0.0003
Epoch [870/1250], Test Loss: 0.0014
Model saved at epoch 870.
Epoch [871/1250], Training Loss: 0.0003
Epoch [871/1250], Test Loss: 0.0013
Epoch [872/1250], Training Loss: 0.0003
Epoch [872/1250], Test Loss: 0.0016
Epoch [873/1250], Training Loss: 0.0003
Epoch [873/1250], Test Loss: 0.0015
Epoch [874/1250], Training Loss: 0.0003
Epoch [874/1250], Test Loss: 0.0013
Epoch [875/1250], Training Loss: 0.0003
Epoch [875/1250], Test Loss: 0.0019
Epoch [876/1250], Training Loss: 0.0003
Epoch [876/1250], Test Loss: 0.0014
Epoch [877/1250], Training Loss: 0.0003
Epoch [877/1250], Test Loss: 0.0017
Epoch [878/1250], Training Loss: 0.0003
Epoch [878/1250], Test Loss: 0.0018
Epoch [879/1250], Training Loss: 0.0003
Epoch [879/1250], Test Loss: 0.0018
Epoch [880/1250], Training Loss: 0.0003
Epoch [880/1250], Test Loss: 0.0019
Model saved at epoch 880.
Epoch [881/1250], Training Loss: 0.0003
Epoch [881/1250], Test Loss: 0.0015
Epoch [882/1250], Training Loss: 0.0003
Epoch [882/1250], Test Loss: 0.0016
Epoch [883/1250], Training Loss: 0.0003
Epoch [883/1250], Test Loss: 0.0014
Epoch [884/1250], Training Loss: 0.0003
Epoch [884/1250], Test Loss: 0.0015
Epoch [885/1250], Training Loss: 0.0003
Epoch [885/1250], Test Loss: 0.0015
Epoch [886/1250], Training Loss: 0.0003
Epoch [886/1250], Test Loss: 0.0019
Epoch [887/1250], Training Loss: 0.0003
Epoch [887/1250], Test Loss: 0.0018
Epoch [888/1250], Training Loss: 0.0003
Epoch [888/1250], Test Loss: 0.0017
Epoch [889/1250], Training Loss: 0.0003
Epoch [889/1250], Test Loss: 0.0016
Epoch [890/1250], Training Loss: 0.0003
Epoch [890/1250], Test Loss: 0.0013
Model saved at epoch 890.
Epoch [891/1250], Training Loss: 0.0003
Epoch [891/1250], Test Loss: 0.0015
Epoch [892/1250], Training Loss: 0.0003
Epoch [892/1250], Test Loss: 0.0015
Epoch [893/1250], Training Loss: 0.0003
Epoch [893/1250], Test Loss: 0.0017
Epoch [894/1250], Training Loss: 0.0003
Epoch [894/1250], Test Loss: 0.0011
Epoch [895/1250], Training Loss: 0.0003
Epoch [895/1250], Test Loss: 0.0015
Epoch [896/1250], Training Loss: 0.0003
Epoch [896/1250], Test Loss: 0.0012
Epoch [897/1250], Training Loss: 0.0003
Epoch [897/1250], Test Loss: 0.0020
Epoch [898/1250], Training Loss: 0.0003
Epoch [898/1250], Test Loss: 0.0015
Epoch [899/1250], Training Loss: 0.0004
Epoch [899/1250], Test Loss: 0.0016
Epoch [900/1250], Training Loss: 0.0004
Epoch [900/1250], Test Loss: 0.0014
Model saved at epoch 900.
Epoch [901/1250], Training Loss: 0.0004
Epoch [901/1250], Test Loss: 0.0016
Epoch [902/1250], Training Loss: 0.0003
Epoch [902/1250], Test Loss: 0.0015
Epoch [903/1250], Training Loss: 0.0003
Epoch [903/1250], Test Loss: 0.0017
Epoch [904/1250], Training Loss: 0.0003
Epoch [904/1250], Test Loss: 0.0015
Epoch [905/1250], Training Loss: 0.0003
Epoch [905/1250], Test Loss: 0.0020
Epoch [906/1250], Training Loss: 0.0003
Epoch [906/1250], Test Loss: 0.0016
Epoch [907/1250], Training Loss: 0.0003
Epoch [907/1250], Test Loss: 0.0014
Epoch [908/1250], Training Loss: 0.0003
Epoch [908/1250], Test Loss: 0.0016
Epoch [909/1250], Training Loss: 0.0003
Epoch [909/1250], Test Loss: 0.0016
Epoch [910/1250], Training Loss: 0.0003
Epoch [910/1250], Test Loss: 0.0015
Model saved at epoch 910.
Epoch [911/1250], Training Loss: 0.0003
Epoch [911/1250], Test Loss: 0.0014
Epoch [912/1250], Training Loss: 0.0003
Epoch [912/1250], Test Loss: 0.0013
Epoch [913/1250], Training Loss: 0.0003
Epoch [913/1250], Test Loss: 0.0015
Epoch [914/1250], Training Loss: 0.0003
Epoch [914/1250], Test Loss: 0.0013
Epoch [915/1250], Training Loss: 0.0003
Epoch [915/1250], Test Loss: 0.0014
Epoch [916/1250], Training Loss: 0.0003
Epoch [916/1250], Test Loss: 0.0015
Epoch [917/1250], Training Loss: 0.0003
Epoch [917/1250], Test Loss: 0.0020
Epoch [918/1250], Training Loss: 0.0003
Epoch [918/1250], Test Loss: 0.0013
Epoch [919/1250], Training Loss: 0.0003
Epoch [919/1250], Test Loss: 0.0021
Epoch [920/1250], Training Loss: 0.0005
Epoch [920/1250], Test Loss: 0.0015
Model saved at epoch 920.
Epoch [921/1250], Training Loss: 0.0005
Epoch [921/1250], Test Loss: 0.0017
Epoch [922/1250], Training Loss: 0.0005
Epoch [922/1250], Test Loss: 0.0016
Epoch [923/1250], Training Loss: 0.0003
Epoch [923/1250], Test Loss: 0.0016
Epoch [924/1250], Training Loss: 0.0003
Epoch [924/1250], Test Loss: 0.0016
Epoch [925/1250], Training Loss: 0.0003
Epoch [925/1250], Test Loss: 0.0012
Epoch [926/1250], Training Loss: 0.0003
Epoch [926/1250], Test Loss: 0.0010
Epoch [927/1250], Training Loss: 0.0003
Epoch [927/1250], Test Loss: 0.0015
Epoch [928/1250], Training Loss: 0.0003
Epoch [928/1250], Test Loss: 0.0018
Epoch [929/1250], Training Loss: 0.0003
Epoch [929/1250], Test Loss: 0.0019
Epoch [930/1250], Training Loss: 0.0003
Epoch [930/1250], Test Loss: 0.0015
Model saved at epoch 930.
Epoch [931/1250], Training Loss: 0.0003
Epoch [931/1250], Test Loss: 0.0016
Epoch [932/1250], Training Loss: 0.0003
Epoch [932/1250], Test Loss: 0.0022
Epoch [933/1250], Training Loss: 0.0003
Epoch [933/1250], Test Loss: 0.0014
Epoch [934/1250], Training Loss: 0.0003
Epoch [934/1250], Test Loss: 0.0015
Epoch [935/1250], Training Loss: 0.0003
Epoch [935/1250], Test Loss: 0.0014
Epoch [936/1250], Training Loss: 0.0003
Epoch [936/1250], Test Loss: 0.0016
Epoch [937/1250], Training Loss: 0.0003
Epoch [937/1250], Test Loss: 0.0012
Epoch [938/1250], Training Loss: 0.0003
Epoch [938/1250], Test Loss: 0.0015
Epoch [939/1250], Training Loss: 0.0003
Epoch [939/1250], Test Loss: 0.0014
Epoch [940/1250], Training Loss: 0.0003
Epoch [940/1250], Test Loss: 0.0017
Model saved at epoch 940.
Epoch [941/1250], Training Loss: 0.0003
Epoch [941/1250], Test Loss: 0.0018
Epoch [942/1250], Training Loss: 0.0003
Epoch [942/1250], Test Loss: 0.0011
Epoch [943/1250], Training Loss: 0.0003
Epoch [943/1250], Test Loss: 0.0013
Epoch [944/1250], Training Loss: 0.0003
Epoch [944/1250], Test Loss: 0.0019
Epoch [945/1250], Training Loss: 0.0004
Epoch [945/1250], Test Loss: 0.0018
Epoch [946/1250], Training Loss: 0.0003
Epoch [946/1250], Test Loss: 0.0018
Epoch [947/1250], Training Loss: 0.0003
Epoch [947/1250], Test Loss: 0.0011
Epoch [948/1250], Training Loss: 0.0003
Epoch [948/1250], Test Loss: 0.0014
Epoch [949/1250], Training Loss: 0.0003
Epoch [949/1250], Test Loss: 0.0015
Epoch [950/1250], Training Loss: 0.0003
Epoch [950/1250], Test Loss: 0.0013
Model saved at epoch 950.
Epoch [951/1250], Training Loss: 0.0003
Epoch [951/1250], Test Loss: 0.0012
Epoch [952/1250], Training Loss: 0.0003
Epoch [952/1250], Test Loss: 0.0017
Epoch [953/1250], Training Loss: 0.0003
Epoch [953/1250], Test Loss: 0.0017
Epoch [954/1250], Training Loss: 0.0003
Epoch [954/1250], Test Loss: 0.0017
Epoch [955/1250], Training Loss: 0.0003
Epoch [955/1250], Test Loss: 0.0021
Epoch [956/1250], Training Loss: 0.0003
Epoch [956/1250], Test Loss: 0.0016
Epoch [957/1250], Training Loss: 0.0003
Epoch [957/1250], Test Loss: 0.0016
Epoch [958/1250], Training Loss: 0.0003
Epoch [958/1250], Test Loss: 0.0011
Epoch [959/1250], Training Loss: 0.0003
Epoch [959/1250], Test Loss: 0.0015
Epoch [960/1250], Training Loss: 0.0003
Epoch [960/1250], Test Loss: 0.0015
Model saved at epoch 960.
Epoch [961/1250], Training Loss: 0.0003
Epoch [961/1250], Test Loss: 0.0013
Epoch [962/1250], Training Loss: 0.0003
Epoch [962/1250], Test Loss: 0.0014
Epoch [963/1250], Training Loss: 0.0003
Epoch [963/1250], Test Loss: 0.0018
Epoch [964/1250], Training Loss: 0.0003
Epoch [964/1250], Test Loss: 0.0012
Epoch [965/1250], Training Loss: 0.0003
Epoch [965/1250], Test Loss: 0.0018
Epoch [966/1250], Training Loss: 0.0003
Epoch [966/1250], Test Loss: 0.0014
Epoch [967/1250], Training Loss: 0.0003
Epoch [967/1250], Test Loss: 0.0017
Epoch [968/1250], Training Loss: 0.0003
Epoch [968/1250], Test Loss: 0.0015
Epoch [969/1250], Training Loss: 0.0003
Epoch [969/1250], Test Loss: 0.0017
Epoch [970/1250], Training Loss: 0.0003
Epoch [970/1250], Test Loss: 0.0013
Model saved at epoch 970.
Epoch [971/1250], Training Loss: 0.0003
Epoch [971/1250], Test Loss: 0.0018
Epoch [972/1250], Training Loss: 0.0003
Epoch [972/1250], Test Loss: 0.0013
Epoch [973/1250], Training Loss: 0.0003
Epoch [973/1250], Test Loss: 0.0015
Epoch [974/1250], Training Loss: 0.0003
Epoch [974/1250], Test Loss: 0.0020
Epoch [975/1250], Training Loss: 0.0003
Epoch [975/1250], Test Loss: 0.0012
Epoch [976/1250], Training Loss: 0.0003
Epoch [976/1250], Test Loss: 0.0016
Epoch [977/1250], Training Loss: 0.0003
Epoch [977/1250], Test Loss: 0.0016
Epoch [978/1250], Training Loss: 0.0003
Epoch [978/1250], Test Loss: 0.0015
Epoch [979/1250], Training Loss: 0.0003
Epoch [979/1250], Test Loss: 0.0015
Epoch [980/1250], Training Loss: 0.0003
Epoch [980/1250], Test Loss: 0.0018
Model saved at epoch 980.
Epoch [981/1250], Training Loss: 0.0003
Epoch [981/1250], Test Loss: 0.0017
Epoch [982/1250], Training Loss: 0.0003
Epoch [982/1250], Test Loss: 0.0012
Epoch [983/1250], Training Loss: 0.0003
Epoch [983/1250], Test Loss: 0.0017
Epoch [984/1250], Training Loss: 0.0003
Epoch [984/1250], Test Loss: 0.0017
Epoch [985/1250], Training Loss: 0.0003
Epoch [985/1250], Test Loss: 0.0014
Epoch [986/1250], Training Loss: 0.0003
Epoch [986/1250], Test Loss: 0.0016
Epoch [987/1250], Training Loss: 0.0003
Epoch [987/1250], Test Loss: 0.0014
Epoch [988/1250], Training Loss: 0.0003
Epoch [988/1250], Test Loss: 0.0015
Epoch [989/1250], Training Loss: 0.0003
Epoch [989/1250], Test Loss: 0.0014
Epoch [990/1250], Training Loss: 0.0003
Epoch [990/1250], Test Loss: 0.0017
Model saved at epoch 990.
Epoch [991/1250], Training Loss: 0.0003
Epoch [991/1250], Test Loss: 0.0013
Epoch [992/1250], Training Loss: 0.0003
Epoch [992/1250], Test Loss: 0.0013
Epoch [993/1250], Training Loss: 0.0003
Epoch [993/1250], Test Loss: 0.0017
Epoch [994/1250], Training Loss: 0.0003
Epoch [994/1250], Test Loss: 0.0010
Epoch [995/1250], Training Loss: 0.0003
Epoch [995/1250], Test Loss: 0.0021
Epoch [996/1250], Training Loss: 0.0003
Epoch [996/1250], Test Loss: 0.0018
Epoch [997/1250], Training Loss: 0.0003
Epoch [997/1250], Test Loss: 0.0015
Epoch [998/1250], Training Loss: 0.0003
Epoch [998/1250], Test Loss: 0.0018
Epoch [999/1250], Training Loss: 0.0003
Epoch [999/1250], Test Loss: 0.0017
Epoch [1000/1250], Training Loss: 0.0003
Epoch [1000/1250], Test Loss: 0.0016
Model saved at epoch 1000.
Epoch [1001/1250], Training Loss: 0.0003
Epoch [1001/1250], Test Loss: 0.0016
Epoch [1002/1250], Training Loss: 0.0003
Epoch [1002/1250], Test Loss: 0.0012
Epoch [1003/1250], Training Loss: 0.0003
Epoch [1003/1250], Test Loss: 0.0012
Epoch [1004/1250], Training Loss: 0.0003
Epoch [1004/1250], Test Loss: 0.0016
Epoch [1005/1250], Training Loss: 0.0003
Epoch [1005/1250], Test Loss: 0.0016
Epoch [1006/1250], Training Loss: 0.0003
Epoch [1006/1250], Test Loss: 0.0016
Epoch [1007/1250], Training Loss: 0.0003
Epoch [1007/1250], Test Loss: 0.0014
Epoch [1008/1250], Training Loss: 0.0003
Epoch [1008/1250], Test Loss: 0.0016
Epoch [1009/1250], Training Loss: 0.0003
Epoch [1009/1250], Test Loss: 0.0017
Epoch [1010/1250], Training Loss: 0.0003
Epoch [1010/1250], Test Loss: 0.0016
Model saved at epoch 1010.
Epoch [1011/1250], Training Loss: 0.0003
Epoch [1011/1250], Test Loss: 0.0017
Epoch [1012/1250], Training Loss: 0.0003
Epoch [1012/1250], Test Loss: 0.0017
Epoch [1013/1250], Training Loss: 0.0003
Epoch [1013/1250], Test Loss: 0.0016
Epoch [1014/1250], Training Loss: 0.0003
Epoch [1014/1250], Test Loss: 0.0017
Epoch [1015/1250], Training Loss: 0.0003
Epoch [1015/1250], Test Loss: 0.0014
Epoch [1016/1250], Training Loss: 0.0003
Epoch [1016/1250], Test Loss: 0.0017
Epoch [1017/1250], Training Loss: 0.0003
Epoch [1017/1250], Test Loss: 0.0016
Epoch [1018/1250], Training Loss: 0.0003
Epoch [1018/1250], Test Loss: 0.0013
Epoch [1019/1250], Training Loss: 0.0003
Epoch [1019/1250], Test Loss: 0.0016
Epoch [1020/1250], Training Loss: 0.0003
Epoch [1020/1250], Test Loss: 0.0018
Model saved at epoch 1020.
Epoch [1021/1250], Training Loss: 0.0003
Epoch [1021/1250], Test Loss: 0.0015
Epoch [1022/1250], Training Loss: 0.0003
Epoch [1022/1250], Test Loss: 0.0013
Epoch [1023/1250], Training Loss: 0.0003
Epoch [1023/1250], Test Loss: 0.0020
Epoch [1024/1250], Training Loss: 0.0003
Epoch [1024/1250], Test Loss: 0.0014
Epoch [1025/1250], Training Loss: 0.0003
Epoch [1025/1250], Test Loss: 0.0016
Epoch [1026/1250], Training Loss: 0.0003
Epoch [1026/1250], Test Loss: 0.0019
Epoch [1027/1250], Training Loss: 0.0003
Epoch [1027/1250], Test Loss: 0.0015
Epoch [1028/1250], Training Loss: 0.0003
Epoch [1028/1250], Test Loss: 0.0014
Epoch [1029/1250], Training Loss: 0.0003
Epoch [1029/1250], Test Loss: 0.0019
Epoch [1030/1250], Training Loss: 0.0003
Epoch [1030/1250], Test Loss: 0.0017
Model saved at epoch 1030.
Epoch [1031/1250], Training Loss: 0.0003
Epoch [1031/1250], Test Loss: 0.0011
Epoch [1032/1250], Training Loss: 0.0003
Epoch [1032/1250], Test Loss: 0.0017
Epoch [1033/1250], Training Loss: 0.0003
Epoch [1033/1250], Test Loss: 0.0018
Epoch [1034/1250], Training Loss: 0.0003
Epoch [1034/1250], Test Loss: 0.0014
Epoch [1035/1250], Training Loss: 0.0003
Epoch [1035/1250], Test Loss: 0.0018
Epoch [1036/1250], Training Loss: 0.0003
Epoch [1036/1250], Test Loss: 0.0016
Epoch [1037/1250], Training Loss: 0.0003
Epoch [1037/1250], Test Loss: 0.0015
Epoch [1038/1250], Training Loss: 0.0003
Epoch [1038/1250], Test Loss: 0.0013
Epoch [1039/1250], Training Loss: 0.0003
Epoch [1039/1250], Test Loss: 0.0013
Epoch [1040/1250], Training Loss: 0.0003
Epoch [1040/1250], Test Loss: 0.0014
Model saved at epoch 1040.
Epoch [1041/1250], Training Loss: 0.0003
Epoch [1041/1250], Test Loss: 0.0014
Epoch [1042/1250], Training Loss: 0.0003
Epoch [1042/1250], Test Loss: 0.0014
Epoch [1043/1250], Training Loss: 0.0003
Epoch [1043/1250], Test Loss: 0.0013
Epoch [1044/1250], Training Loss: 0.0003
Epoch [1044/1250], Test Loss: 0.0015
Epoch [1045/1250], Training Loss: 0.0003
Epoch [1045/1250], Test Loss: 0.0015
Epoch [1046/1250], Training Loss: 0.0003
Epoch [1046/1250], Test Loss: 0.0017
Epoch [1047/1250], Training Loss: 0.0003
Epoch [1047/1250], Test Loss: 0.0015
Epoch [1048/1250], Training Loss: 0.0003
Epoch [1048/1250], Test Loss: 0.0015
Epoch [1049/1250], Training Loss: 0.0003
Epoch [1049/1250], Test Loss: 0.0018
Epoch [1050/1250], Training Loss: 0.0003
Epoch [1050/1250], Test Loss: 0.0013
Model saved at epoch 1050.
Epoch [1051/1250], Training Loss: 0.0003
Epoch [1051/1250], Test Loss: 0.0016
Epoch [1052/1250], Training Loss: 0.0003
Epoch [1052/1250], Test Loss: 0.0015
Epoch [1053/1250], Training Loss: 0.0003
Epoch [1053/1250], Test Loss: 0.0020
Epoch [1054/1250], Training Loss: 0.0003
Epoch [1054/1250], Test Loss: 0.0016
Epoch [1055/1250], Training Loss: 0.0003
Epoch [1055/1250], Test Loss: 0.0014
Epoch [1056/1250], Training Loss: 0.0003
Epoch [1056/1250], Test Loss: 0.0016
Epoch [1057/1250], Training Loss: 0.0003
Epoch [1057/1250], Test Loss: 0.0015
Epoch [1058/1250], Training Loss: 0.0003
Epoch [1058/1250], Test Loss: 0.0018
Epoch [1059/1250], Training Loss: 0.0003
Epoch [1059/1250], Test Loss: 0.0016
Epoch [1060/1250], Training Loss: 0.0003
Epoch [1060/1250], Test Loss: 0.0012
Model saved at epoch 1060.
Epoch [1061/1250], Training Loss: 0.0003
Epoch [1061/1250], Test Loss: 0.0015
Epoch [1062/1250], Training Loss: 0.0003
Epoch [1062/1250], Test Loss: 0.0016
Epoch [1063/1250], Training Loss: 0.0003
Epoch [1063/1250], Test Loss: 0.0016
Epoch [1064/1250], Training Loss: 0.0003
Epoch [1064/1250], Test Loss: 0.0016
Epoch [1065/1250], Training Loss: 0.0003
Epoch [1065/1250], Test Loss: 0.0017
Epoch [1066/1250], Training Loss: 0.0003
Epoch [1066/1250], Test Loss: 0.0014
Epoch [1067/1250], Training Loss: 0.0003
Epoch [1067/1250], Test Loss: 0.0017
Epoch [1068/1250], Training Loss: 0.0003
Epoch [1068/1250], Test Loss: 0.0016
Epoch [1069/1250], Training Loss: 0.0003
Epoch [1069/1250], Test Loss: 0.0016
Epoch [1070/1250], Training Loss: 0.0003
Epoch [1070/1250], Test Loss: 0.0016
Model saved at epoch 1070.
Epoch [1071/1250], Training Loss: 0.0003
Epoch [1071/1250], Test Loss: 0.0013
Epoch [1072/1250], Training Loss: 0.0003
Epoch [1072/1250], Test Loss: 0.0016
Epoch [1073/1250], Training Loss: 0.0003
Epoch [1073/1250], Test Loss: 0.0013
Epoch [1074/1250], Training Loss: 0.0003
Epoch [1074/1250], Test Loss: 0.0021
Epoch [1075/1250], Training Loss: 0.0003
Epoch [1075/1250], Test Loss: 0.0017
Epoch [1076/1250], Training Loss: 0.0003
Epoch [1076/1250], Test Loss: 0.0012
Epoch [1077/1250], Training Loss: 0.0003
Epoch [1077/1250], Test Loss: 0.0017
Epoch [1078/1250], Training Loss: 0.0003
Epoch [1078/1250], Test Loss: 0.0016
Epoch [1079/1250], Training Loss: 0.0003
Epoch [1079/1250], Test Loss: 0.0014
Epoch [1080/1250], Training Loss: 0.0003
Epoch [1080/1250], Test Loss: 0.0018
Model saved at epoch 1080.
Epoch [1081/1250], Training Loss: 0.0003
Epoch [1081/1250], Test Loss: 0.0023
Epoch [1082/1250], Training Loss: 0.0004
Epoch [1082/1250], Test Loss: 0.0021
Epoch [1083/1250], Training Loss: 0.0004
Epoch [1083/1250], Test Loss: 0.0019
Epoch [1084/1250], Training Loss: 0.0003
Epoch [1084/1250], Test Loss: 0.0012
Epoch [1085/1250], Training Loss: 0.0003
Epoch [1085/1250], Test Loss: 0.0013
Epoch [1086/1250], Training Loss: 0.0003
Epoch [1086/1250], Test Loss: 0.0017
Epoch [1087/1250], Training Loss: 0.0003
Epoch [1087/1250], Test Loss: 0.0013
Epoch [1088/1250], Training Loss: 0.0003
Epoch [1088/1250], Test Loss: 0.0016
Epoch [1089/1250], Training Loss: 0.0003
Epoch [1089/1250], Test Loss: 0.0012
Epoch [1090/1250], Training Loss: 0.0003
Epoch [1090/1250], Test Loss: 0.0013
Model saved at epoch 1090.
Epoch [1091/1250], Training Loss: 0.0003
Epoch [1091/1250], Test Loss: 0.0017
Epoch [1092/1250], Training Loss: 0.0003
Epoch [1092/1250], Test Loss: 0.0018
Epoch [1093/1250], Training Loss: 0.0003
Epoch [1093/1250], Test Loss: 0.0012
Epoch [1094/1250], Training Loss: 0.0003
Epoch [1094/1250], Test Loss: 0.0015
Epoch [1095/1250], Training Loss: 0.0003
Epoch [1095/1250], Test Loss: 0.0017
Epoch [1096/1250], Training Loss: 0.0003
Epoch [1096/1250], Test Loss: 0.0015
Epoch [1097/1250], Training Loss: 0.0003
Epoch [1097/1250], Test Loss: 0.0016
Epoch [1098/1250], Training Loss: 0.0003
Epoch [1098/1250], Test Loss: 0.0017
Epoch [1099/1250], Training Loss: 0.0003
Epoch [1099/1250], Test Loss: 0.0015
Epoch [1100/1250], Training Loss: 0.0003
Epoch [1100/1250], Test Loss: 0.0016
Model saved at epoch 1100.
Epoch [1101/1250], Training Loss: 0.0003
Epoch [1101/1250], Test Loss: 0.0014
Epoch [1102/1250], Training Loss: 0.0003
Epoch [1102/1250], Test Loss: 0.0016
Epoch [1103/1250], Training Loss: 0.0003
Epoch [1103/1250], Test Loss: 0.0015
Epoch [1104/1250], Training Loss: 0.0003
Epoch [1104/1250], Test Loss: 0.0018
Epoch [1105/1250], Training Loss: 0.0003
Epoch [1105/1250], Test Loss: 0.0017
Epoch [1106/1250], Training Loss: 0.0003
Epoch [1106/1250], Test Loss: 0.0013
Epoch [1107/1250], Training Loss: 0.0003
Epoch [1107/1250], Test Loss: 0.0016
Epoch [1108/1250], Training Loss: 0.0003
Epoch [1108/1250], Test Loss: 0.0013
Epoch [1109/1250], Training Loss: 0.0003
Epoch [1109/1250], Test Loss: 0.0018
Epoch [1110/1250], Training Loss: 0.0003
Epoch [1110/1250], Test Loss: 0.0014
Model saved at epoch 1110.
Epoch [1111/1250], Training Loss: 0.0003
Epoch [1111/1250], Test Loss: 0.0015
Epoch [1112/1250], Training Loss: 0.0003
Epoch [1112/1250], Test Loss: 0.0016
Epoch [1113/1250], Training Loss: 0.0003
Epoch [1113/1250], Test Loss: 0.0020
Epoch [1114/1250], Training Loss: 0.0003
Epoch [1114/1250], Test Loss: 0.0016
Epoch [1115/1250], Training Loss: 0.0003
Epoch [1115/1250], Test Loss: 0.0019
Epoch [1116/1250], Training Loss: 0.0003
Epoch [1116/1250], Test Loss: 0.0016
Epoch [1117/1250], Training Loss: 0.0003
Epoch [1117/1250], Test Loss: 0.0014
Epoch [1118/1250], Training Loss: 0.0003
Epoch [1118/1250], Test Loss: 0.0014
Epoch [1119/1250], Training Loss: 0.0003
Epoch [1119/1250], Test Loss: 0.0011
Epoch [1120/1250], Training Loss: 0.0003
Epoch [1120/1250], Test Loss: 0.0014
Model saved at epoch 1120.
Epoch [1121/1250], Training Loss: 0.0003
Epoch [1121/1250], Test Loss: 0.0014
Epoch [1122/1250], Training Loss: 0.0003
Epoch [1122/1250], Test Loss: 0.0014
Epoch [1123/1250], Training Loss: 0.0002
Epoch [1123/1250], Test Loss: 0.0014
Epoch [1124/1250], Training Loss: 0.0003
Epoch [1124/1250], Test Loss: 0.0017
Epoch [1125/1250], Training Loss: 0.0003
Epoch [1125/1250], Test Loss: 0.0017
Epoch [1126/1250], Training Loss: 0.0003
Epoch [1126/1250], Test Loss: 0.0014
Epoch [1127/1250], Training Loss: 0.0003
Epoch [1127/1250], Test Loss: 0.0013
Epoch [1128/1250], Training Loss: 0.0003
Epoch [1128/1250], Test Loss: 0.0015
Epoch [1129/1250], Training Loss: 0.0003
Epoch [1129/1250], Test Loss: 0.0015
Epoch [1130/1250], Training Loss: 0.0003
Epoch [1130/1250], Test Loss: 0.0015
Model saved at epoch 1130.
Epoch [1131/1250], Training Loss: 0.0003
Epoch [1131/1250], Test Loss: 0.0013
Epoch [1132/1250], Training Loss: 0.0003
Epoch [1132/1250], Test Loss: 0.0013
Epoch [1133/1250], Training Loss: 0.0003
Epoch [1133/1250], Test Loss: 0.0013
Epoch [1134/1250], Training Loss: 0.0003
Epoch [1134/1250], Test Loss: 0.0019
Epoch [1135/1250], Training Loss: 0.0003
Epoch [1135/1250], Test Loss: 0.0019
Epoch [1136/1250], Training Loss: 0.0002
Epoch [1136/1250], Test Loss: 0.0016
Epoch [1137/1250], Training Loss: 0.0003
Epoch [1137/1250], Test Loss: 0.0021
Epoch [1138/1250], Training Loss: 0.0003
Epoch [1138/1250], Test Loss: 0.0020
Epoch [1139/1250], Training Loss: 0.0003
Epoch [1139/1250], Test Loss: 0.0016
Epoch [1140/1250], Training Loss: 0.0003
Epoch [1140/1250], Test Loss: 0.0014
Model saved at epoch 1140.
Epoch [1141/1250], Training Loss: 0.0003
Epoch [1141/1250], Test Loss: 0.0012
Epoch [1142/1250], Training Loss: 0.0003
Epoch [1142/1250], Test Loss: 0.0017
Epoch [1143/1250], Training Loss: 0.0003
Epoch [1143/1250], Test Loss: 0.0014
Epoch [1144/1250], Training Loss: 0.0003
Epoch [1144/1250], Test Loss: 0.0014
Epoch [1145/1250], Training Loss: 0.0003
Epoch [1145/1250], Test Loss: 0.0016
Epoch [1146/1250], Training Loss: 0.0003
Epoch [1146/1250], Test Loss: 0.0011
Epoch [1147/1250], Training Loss: 0.0003
Epoch [1147/1250], Test Loss: 0.0013
Epoch [1148/1250], Training Loss: 0.0003
Epoch [1148/1250], Test Loss: 0.0016
Epoch [1149/1250], Training Loss: 0.0003
Epoch [1149/1250], Test Loss: 0.0016
Epoch [1150/1250], Training Loss: 0.0003
Epoch [1150/1250], Test Loss: 0.0019
Model saved at epoch 1150.
Epoch [1151/1250], Training Loss: 0.0003
Epoch [1151/1250], Test Loss: 0.0016
Epoch [1152/1250], Training Loss: 0.0003
Epoch [1152/1250], Test Loss: 0.0016
Epoch [1153/1250], Training Loss: 0.0003
Epoch [1153/1250], Test Loss: 0.0013
Epoch [1154/1250], Training Loss: 0.0003
Epoch [1154/1250], Test Loss: 0.0019
Epoch [1155/1250], Training Loss: 0.0003
Epoch [1155/1250], Test Loss: 0.0017
Epoch [1156/1250], Training Loss: 0.0003
Epoch [1156/1250], Test Loss: 0.0015
Epoch [1157/1250], Training Loss: 0.0003
Epoch [1157/1250], Test Loss: 0.0016
Epoch [1158/1250], Training Loss: 0.0003
Epoch [1158/1250], Test Loss: 0.0018
Epoch [1159/1250], Training Loss: 0.0003
Epoch [1159/1250], Test Loss: 0.0015
Epoch [1160/1250], Training Loss: 0.0003
Epoch [1160/1250], Test Loss: 0.0013
Model saved at epoch 1160.
Epoch [1161/1250], Training Loss: 0.0003
Epoch [1161/1250], Test Loss: 0.0016
Epoch [1162/1250], Training Loss: 0.0003
Epoch [1162/1250], Test Loss: 0.0017
Epoch [1163/1250], Training Loss: 0.0003
Epoch [1163/1250], Test Loss: 0.0016
Epoch [1164/1250], Training Loss: 0.0003
Epoch [1164/1250], Test Loss: 0.0015
Epoch [1165/1250], Training Loss: 0.0003
Epoch [1165/1250], Test Loss: 0.0014
Epoch [1166/1250], Training Loss: 0.0003
Epoch [1166/1250], Test Loss: 0.0016
Epoch [1167/1250], Training Loss: 0.0003
Epoch [1167/1250], Test Loss: 0.0014
Epoch [1168/1250], Training Loss: 0.0003
Epoch [1168/1250], Test Loss: 0.0017
Epoch [1169/1250], Training Loss: 0.0003
Epoch [1169/1250], Test Loss: 0.0017
Epoch [1170/1250], Training Loss: 0.0003
Epoch [1170/1250], Test Loss: 0.0020
Model saved at epoch 1170.
Epoch [1171/1250], Training Loss: 0.0003
Epoch [1171/1250], Test Loss: 0.0015
Epoch [1172/1250], Training Loss: 0.0003
Epoch [1172/1250], Test Loss: 0.0016
Epoch [1173/1250], Training Loss: 0.0003
Epoch [1173/1250], Test Loss: 0.0012
Epoch [1174/1250], Training Loss: 0.0003
Epoch [1174/1250], Test Loss: 0.0014
Epoch [1175/1250], Training Loss: 0.0003
Epoch [1175/1250], Test Loss: 0.0014
Epoch [1176/1250], Training Loss: 0.0003
Epoch [1176/1250], Test Loss: 0.0012
Epoch [1177/1250], Training Loss: 0.0003
Epoch [1177/1250], Test Loss: 0.0013
Epoch [1178/1250], Training Loss: 0.0003
Epoch [1178/1250], Test Loss: 0.0018
Epoch [1179/1250], Training Loss: 0.0003
Epoch [1179/1250], Test Loss: 0.0016
Epoch [1180/1250], Training Loss: 0.0002
Epoch [1180/1250], Test Loss: 0.0014
Model saved at epoch 1180.
Epoch [1181/1250], Training Loss: 0.0003
Epoch [1181/1250], Test Loss: 0.0018
Epoch [1182/1250], Training Loss: 0.0003
Epoch [1182/1250], Test Loss: 0.0015
Epoch [1183/1250], Training Loss: 0.0003
Epoch [1183/1250], Test Loss: 0.0013
Epoch [1184/1250], Training Loss: 0.0003
Epoch [1184/1250], Test Loss: 0.0016
Epoch [1185/1250], Training Loss: 0.0003
Epoch [1185/1250], Test Loss: 0.0014
Epoch [1186/1250], Training Loss: 0.0003
Epoch [1186/1250], Test Loss: 0.0015
Epoch [1187/1250], Training Loss: 0.0003
Epoch [1187/1250], Test Loss: 0.0019
Epoch [1188/1250], Training Loss: 0.0003
Epoch [1188/1250], Test Loss: 0.0015
Epoch [1189/1250], Training Loss: 0.0003
Epoch [1189/1250], Test Loss: 0.0015
Epoch [1190/1250], Training Loss: 0.0003
Epoch [1190/1250], Test Loss: 0.0016
Model saved at epoch 1190.
Epoch [1191/1250], Training Loss: 0.0003
Epoch [1191/1250], Test Loss: 0.0011
Epoch [1192/1250], Training Loss: 0.0003
Epoch [1192/1250], Test Loss: 0.0015
Epoch [1193/1250], Training Loss: 0.0003
Epoch [1193/1250], Test Loss: 0.0014
Epoch [1194/1250], Training Loss: 0.0003
Epoch [1194/1250], Test Loss: 0.0020
Epoch [1195/1250], Training Loss: 0.0003
Epoch [1195/1250], Test Loss: 0.0017
Epoch [1196/1250], Training Loss: 0.0003
Epoch [1196/1250], Test Loss: 0.0016
Epoch [1197/1250], Training Loss: 0.0003
Epoch [1197/1250], Test Loss: 0.0019
Epoch [1198/1250], Training Loss: 0.0003
Epoch [1198/1250], Test Loss: 0.0015
Epoch [1199/1250], Training Loss: 0.0003
Epoch [1199/1250], Test Loss: 0.0020
Epoch [1200/1250], Training Loss: 0.0003
Epoch [1200/1250], Test Loss: 0.0016
Model saved at epoch 1200.
Epoch [1201/1250], Training Loss: 0.0003
Epoch [1201/1250], Test Loss: 0.0017
Epoch [1202/1250], Training Loss: 0.0003
Epoch [1202/1250], Test Loss: 0.0013
Epoch [1203/1250], Training Loss: 0.0003
Epoch [1203/1250], Test Loss: 0.0012
Epoch [1204/1250], Training Loss: 0.0003
Epoch [1204/1250], Test Loss: 0.0017
Epoch [1205/1250], Training Loss: 0.0003
Epoch [1205/1250], Test Loss: 0.0015
Epoch [1206/1250], Training Loss: 0.0003
Epoch [1206/1250], Test Loss: 0.0011
Epoch [1207/1250], Training Loss: 0.0003
Epoch [1207/1250], Test Loss: 0.0016
Epoch [1208/1250], Training Loss: 0.0003
Epoch [1208/1250], Test Loss: 0.0014
Epoch [1209/1250], Training Loss: 0.0002
Epoch [1209/1250], Test Loss: 0.0014
Epoch [1210/1250], Training Loss: 0.0002
Epoch [1210/1250], Test Loss: 0.0013
Model saved at epoch 1210.
Epoch [1211/1250], Training Loss: 0.0003
Epoch [1211/1250], Test Loss: 0.0017
Epoch [1212/1250], Training Loss: 0.0003
Epoch [1212/1250], Test Loss: 0.0014
Epoch [1213/1250], Training Loss: 0.0003
Epoch [1213/1250], Test Loss: 0.0016
Epoch [1214/1250], Training Loss: 0.0003
Epoch [1214/1250], Test Loss: 0.0014
Epoch [1215/1250], Training Loss: 0.0003
Epoch [1215/1250], Test Loss: 0.0017
Epoch [1216/1250], Training Loss: 0.0003
Epoch [1216/1250], Test Loss: 0.0020
Epoch [1217/1250], Training Loss: 0.0003
Epoch [1217/1250], Test Loss: 0.0018
Epoch [1218/1250], Training Loss: 0.0003
Epoch [1218/1250], Test Loss: 0.0016
Epoch [1219/1250], Training Loss: 0.0003
Epoch [1219/1250], Test Loss: 0.0014
Epoch [1220/1250], Training Loss: 0.0003
Epoch [1220/1250], Test Loss: 0.0018
Model saved at epoch 1220.
Epoch [1221/1250], Training Loss: 0.0003
Epoch [1221/1250], Test Loss: 0.0018
Epoch [1222/1250], Training Loss: 0.0002
Epoch [1222/1250], Test Loss: 0.0016
Epoch [1223/1250], Training Loss: 0.0003
Epoch [1223/1250], Test Loss: 0.0018
Epoch [1224/1250], Training Loss: 0.0002
Epoch [1224/1250], Test Loss: 0.0013
Epoch [1225/1250], Training Loss: 0.0002
Epoch [1225/1250], Test Loss: 0.0013
Epoch [1226/1250], Training Loss: 0.0003
Epoch [1226/1250], Test Loss: 0.0016
Epoch [1227/1250], Training Loss: 0.0003
Epoch [1227/1250], Test Loss: 0.0014
Epoch [1228/1250], Training Loss: 0.0003
Epoch [1228/1250], Test Loss: 0.0018
Epoch [1229/1250], Training Loss: 0.0003
Epoch [1229/1250], Test Loss: 0.0014
Epoch [1230/1250], Training Loss: 0.0003
Epoch [1230/1250], Test Loss: 0.0017
Model saved at epoch 1230.
Epoch [1231/1250], Training Loss: 0.0003
Epoch [1231/1250], Test Loss: 0.0018
Epoch [1232/1250], Training Loss: 0.0003
Epoch [1232/1250], Test Loss: 0.0014
Epoch [1233/1250], Training Loss: 0.0003
Epoch [1233/1250], Test Loss: 0.0013
Epoch [1234/1250], Training Loss: 0.0003
Epoch [1234/1250], Test Loss: 0.0011
Epoch [1235/1250], Training Loss: 0.0003
Epoch [1235/1250], Test Loss: 0.0016
Epoch [1236/1250], Training Loss: 0.0003
Epoch [1236/1250], Test Loss: 0.0017
Epoch [1237/1250], Training Loss: 0.0003
Epoch [1237/1250], Test Loss: 0.0018
Epoch [1238/1250], Training Loss: 0.0003
Epoch [1238/1250], Test Loss: 0.0017
Epoch [1239/1250], Training Loss: 0.0003
Epoch [1239/1250], Test Loss: 0.0011
Epoch [1240/1250], Training Loss: 0.0002
Epoch [1240/1250], Test Loss: 0.0015
Model saved at epoch 1240.
Epoch [1241/1250], Training Loss: 0.0003
Epoch [1241/1250], Test Loss: 0.0016
Epoch [1242/1250], Training Loss: 0.0003
Epoch [1242/1250], Test Loss: 0.0015
Epoch [1243/1250], Training Loss: 0.0003
Epoch [1243/1250], Test Loss: 0.0017
Epoch [1244/1250], Training Loss: 0.0002
Epoch [1244/1250], Test Loss: 0.0016
Epoch [1245/1250], Training Loss: 0.0003
Epoch [1245/1250], Test Loss: 0.0016
Epoch [1246/1250], Training Loss: 0.0003
Epoch [1246/1250], Test Loss: 0.0013
Epoch [1247/1250], Training Loss: 0.0003
Epoch [1247/1250], Test Loss: 0.0016
Epoch [1248/1250], Training Loss: 0.0003
Epoch [1248/1250], Test Loss: 0.0019
Epoch [1249/1250], Training Loss: 0.0003
Epoch [1249/1250], Test Loss: 0.0016
Epoch [1250/1250], Training Loss: 0.0002
Epoch [1250/1250], Test Loss: 0.0016
Model saved at epoch 1250.
